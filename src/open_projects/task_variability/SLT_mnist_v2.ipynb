{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giIyPcmTPUiM"
      },
      "source": [
        "# SERIMATS Application\n",
        "\n",
        "\n",
        "|           |                |\n",
        "| : ----- : | :------------: |\n",
        "| Candidate | Matthieu David |\n",
        "| stream    | developmental interpretability |\n",
        "| subject   | [task variability](https://devinterp.com/projects/task-variability) |\n",
        "\n",
        "\n",
        "\n",
        "This notebook is inspired from the notebook [RLCT Estimation of MNIST](https://colab.research.google.com/github/timaeus-research/devinterp/blob/main/examples/mnist.ipynb) with large change to fit my submission.\n",
        "\n",
        "\n",
        "---\n",
        "## RLCT Estimation of MNIST\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]()\n",
        "\n",
        "This Jupyter Notebook aims to reproduce the results of Lau et al. (2023) by measuring the Real Log Canonical Threshold (RLCT) for a small 2-layer ReLU model (about 1M parameters) trained on the MNIST dataset. It uses both Stochastic Gradient Nose-Hoover Thermostat (SGNHT) and Stochastic Gradient Langevin Dynamics (SGLD) as sampling methods.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents:\n",
        "* packages installation\n",
        "* Import for the all notebook\n",
        "* Method definitions\n",
        "* Experiments 1 (XP1): Impact of the number of classes\n",
        "    * Toy model and Resnet18 instances\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 2$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 3$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 4$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 5$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 6$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 10$\n",
        "* Displays $Î»\\ vs\\ \\mathcal{L}abels$\n",
        "* Experiments 2 (XP2): Impact of the data diversity (not perform due to time limitation in instruction)\n",
        "* Experiments 3 (XP3): Impact of the number of classes (not perform due to time limitation in instruction)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7SG-MJmEAb"
      },
      "source": [
        "## Package installation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qveJHrTCwxiR",
        "outputId": "d27812d3-79af-4246-f7ab-4e7dbe618ca0"
      },
      "outputs": [],
      "source": [
        "%pip install devinterp matplotlib seaborn torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndBsAQfymIpo"
      },
      "source": [
        "## Import for all the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQsK8RymwxiS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "from typing import Literal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pydantic.types import confloat, conint\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from devinterp.optim.sgld import SGLD\n",
        "from devinterp.optim.sgnht import SGNHT\n",
        "from devinterp.slt import estimate_learning_coeff\n",
        "\n",
        "PRIMARY, SECONDARY, TERTIARY = sns.color_palette(\"muted\")[:3]\n",
        "PRIMARY_LIGHT, SECONDARY_LIGHT, TERTIARY_LIGHT = sns.color_palette(\"pastel\")[:3]\n",
        "sns.set_theme(\"paper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1LHW2tDmPef"
      },
      "source": [
        "## Method definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hznyDuvMoCM4"
      },
      "source": [
        "#### Class of the Toy model:\n",
        "The toy model corresponds to the initial model used in the notebook RLCT Estimation of MNIST (rewrite a little for lisibility). This model is made of 2 linear layers, each activations being a ReLU function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LqUSR-nwxiS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the toy neural network\n",
        "class OriginalToyNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes=[1024, 1024],\n",
        "        input_dim=28 * 28,\n",
        "        output_dim=10,\n",
        "        activation=F.relu,\n",
        "        with_bias=True,\n",
        "    ):\n",
        "        super(OriginalToyNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.layer_sizes = [input_dim] + hidden_layer_sizes + [output_dim]\n",
        "        self.activation = activation\n",
        "        self.with_bias = with_bias\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(self.layer_sizes) - 1):\n",
        "            dim_in, dim_out = self.layer_sizes[i : i + 2]\n",
        "            self.layers.append(nn.Linear(dim_in, dim_out, bias=self.with_bias).float())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "# Define the toy neural network\n",
        "class ToyNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes: list[int]=[1024, 1024],\n",
        "        input_dim: int=28 * 28,\n",
        "        output_dim: int=10,\n",
        "        with_bias: bool=True,\n",
        "    ):\n",
        "        \"\"\"Toy model for task variability experiment\n",
        "\n",
        "        Args:\n",
        "            hidden_layer_sizes (list, optional): list of the size of each hidden layers. Defaults to [1024, 1024].\n",
        "            input_dim (_type_, optional): Width and height of the input data. Defaults to 28*28.\n",
        "            output_dim (int, optional): siez of the output layer. Corresponds to the number of classes. Defaults to 10.\n",
        "            with_bias (bool, optional): allowing biais term or not for each layers. Defaults to True.\n",
        "        \"\"\"\n",
        "        super(ToyNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.with_bias = with_bias\n",
        "        self.layer_sizes = [input_dim] + hidden_layer_sizes + [output_dim]\n",
        "\n",
        "        # First basic block = Linear + ReLU activation\n",
        "        self.fc_1 = nn.Linear(in_features=input_dim, out_features=1024, bias=self.with_bias)\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        # 2nd basic block = Linear + ReLU activation\n",
        "        self.fc_2 = nn.Linear(in_features=1024, out_features=1024, bias=self.with_bias)\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        # Last Fully Connected layer:\n",
        "        self.fc_3 = nn.Linear(in_features=1024, out_features=output_dim, bias=self.with_bias)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Computation performed at every call\n",
        "\n",
        "        Args:\n",
        "            x: input data (batch_size, height, width) propagated through Net\n",
        "\n",
        "        Returns:\n",
        "            output result of x through Net\n",
        "        \"\"\"\n",
        "        x = x.view(-1, self.input_dim)\n",
        "\n",
        "        x = self.fc_1(x)\n",
        "        x = self.relu_1(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = self.relu_2(x)\n",
        "        x = self.relu_2(x)\n",
        "\n",
        "        x = self.fc_3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzAGhKntn_yy"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
        "    \"Original train_one_epoch method from MNIST notebook of timaeus/devinterp\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for data, target in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(DEVICE))\n",
        "        loss = criterion(output, target.to(DEVICE))\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    \"Original evaluate method from MNIST notebook of timaeus/devinterp\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(DEVICE))\n",
        "            loss = criterion(output, target.to(DEVICE))\n",
        "            test_loss += loss.item()\n",
        "    return test_loss / len(test_loader)\n",
        "\n",
        "\n",
        "def train_step(model: nn.Module, optimizer: optim.Optimizer, criterion:nn.modules.loss._Loss, train_set: DataLoader):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to train\n",
        "        optimizer (optim.Optimizer): optimizer to used during training\n",
        "        criterion (nn.modules.loss._Loss): Loss function to use for the training\n",
        "        train_set (DataLoader): train dataloader\n",
        "\n",
        "    Returns:\n",
        "        tuple(average train loss, average train accuracy)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    # model.to(DEVICE)\n",
        "\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    i = 0\n",
        "    prog_bar = tqdm(train_set, desc=f\"\\ttrain_loss: {train_loss:0.2f} -- train_acc: {train_acc:0.2f} %\")\n",
        "    for x, y in prog_bar:\n",
        "        # Stating variables\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        output = model(x) # Forward step\n",
        "        loss = criterion(output, y) # Loss step\n",
        "\n",
        "        # Backward step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accuracy\n",
        "        top_p, prediction = output.topk(1, dim=1)\n",
        "        equals = (prediction == y.view(*prediction.shape))\n",
        "\n",
        "        prog_bar.set_description(f\"\\ttrain_loss: {train_loss / len(train_set) :0.5f} -- train_acc: {100 * train_acc / len(train_set) :0.2f} %\")\n",
        "        # Saving data\n",
        "        train_loss += loss.item()\n",
        "        train_acc += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return train_loss / len(train_set), train_acc / len(train_set)\n",
        "\n",
        "\n",
        "def val_step(model: nn.Module, criterion: nn.modules.loss._Loss, val_set: DataLoader):\n",
        "    \"\"\" Evaluation method. Calculate the loss and accuracy on the hold out data set\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): model to evaluate\n",
        "        criterion (nn.modules.loss._Loss): loss function to use\n",
        "        val_set (DataLoader): evaluation dataloader\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "\n",
        "    model.eval()\n",
        "    # model.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(val_set):\n",
        "            # Stating variables\n",
        "            images = x.to(DEVICE)\n",
        "            labels = y.to(DEVICE)\n",
        "\n",
        "            output = model(images) # Forward step\n",
        "\n",
        "            loss = criterion(output, labels) # Loss step\n",
        "\n",
        "            # Accuracy\n",
        "            top_p, prediction = output.topk(1, dim=1)\n",
        "            equals = (prediction == labels.view(*prediction.shape))\n",
        "\n",
        "            # Saving data\n",
        "            val_loss += loss.item()\n",
        "            val_acc += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return val_loss / len(val_set), val_acc / len(val_set)\n",
        "\n",
        "def print_step_report(epoch:int, train_loss: float, val_loss: float, train_acc: float, val_acc: float):\n",
        "    \"\"\" Utility method to gather printed information\"\"\"\n",
        "    print(f\"Epoch {epoch+1}:\\n\" \\\n",
        "          f\"Train Loss: {train_loss:.5f}\" \\\n",
        "          f\"-- Val Loss: {val_loss:.5f}\" \\\n",
        "          f\"-- Train Acc: {train_acc:0.2f}\" \\\n",
        "          f\"-- Val Acc: {val_acc:0.2f}\")\n",
        "\n",
        "def plot_lambda_vs_epochs(train_losses, test_losses, rlct_estimates_sgnht, rlct_estimates_sgld):\n",
        "    \"\"\" Utility method to manage plot of losses and RLCT coefficient wrt epochs\"\"\"\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\", color=PRIMARY)\n",
        "    ax1.plot(train_losses, label=\"Train Loss\", color=PRIMARY)\n",
        "    ax1.plot(test_losses, label=\"Test Loss\", color=PRIMARY_LIGHT)\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=PRIMARY)\n",
        "    ax1.legend(loc=\"lower left\")\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel(r\"Local Learning Coefficient, $\\hat \\lambda$\", color=SECONDARY)\n",
        "    ax2.plot(rlct_estimates_sgnht, label=\"SGNHT\", color=SECONDARY)\n",
        "    ax2.plot(rlct_estimates_sgld, label=\"SGLD\", color=SECONDARY_LIGHT)\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=SECONDARY)\n",
        "    ax2.legend(loc=\"center right\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoVkYJvmmYVK"
      },
      "source": [
        "## Experiments 1 (XP1): Impact of the number of classes\n",
        "\n",
        "This section contains all the experiments about the XP1 detailled in the application report [here](link)\n",
        "\n",
        "First basic code cells are given the dataset MNIST and basics training with the Toy model and Resnet18 are reported. The readers can explore the core process without modifying the code for the actual experiment.\n",
        "\n",
        "Secondly each sub experiments possess a dedicated sub section , new data loaders are generated, where the labels are rewritten to performed the experiment with the dedicated label set cardinality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ib7yhNmglL"
      },
      "source": [
        "### MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbOo-km8mEmF"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data\n",
        "## definition of the transformation to apply to dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.244, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_data = datasets.MNIST(\"../data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\"../data\", train=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmnLYtMpFArQ"
      },
      "outputs": [],
      "source": [
        "run_toy_model = True\n",
        "run_resnet = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbCKghWUmsk7"
      },
      "source": [
        "### Toy model and Resnet18 instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coSwenPswxiT"
      },
      "outputs": [],
      "source": [
        "# Depending of the run type, cuda or cpu mode is defined\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --------------------------------------------\n",
        "N_CLASSES = 10 # for the 10 class digits of MNIST\n",
        "lr = 0.005\n",
        "n_epochs = 20\n",
        "# --------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    model_resnet18 = resnet18(weights=None).to(DEVICE)\n",
        "\n",
        "    ## changing the last fully connected layer of N neurons, each corresponding to a class.\n",
        "    new_fc_act = nn.Linear(model_resnet18.fc.in_features, N_CLASSES)\n",
        "    model_resnet18.fc = new_fc_act\n",
        "\n",
        "    ## Changing the first conv2d layer to match the input image shape\n",
        "    model_resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    # Loss and optimizer definition\n",
        "    criterion_resnet18 = nn.CrossEntropyLoss()\n",
        "    optimizer_resnet18 = optim.SGD(model_resnet18.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    # Initialize model, loss, optimizer and sgld sampler\n",
        "    model_toy = ToyNet().to(DEVICE)\n",
        "    criterion_toy = nn.CrossEntropyLoss()\n",
        "    optimizer_toy = optim.SGD(model_toy.parameters(), lr=lr, momentum=0.9, nesterov=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sDUnyjFrErX"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy = []\n",
        "    val_losses_toy = []\n",
        "    models_toy = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy.append(train_loss)\n",
        "        val_losses_toy.append(val_loss)\n",
        "        models_toy += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy, \"toy_models.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGRlwa01wxiU"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet = []\n",
        "    val_losses_resnet = []\n",
        "    models_resnet = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet.append(train_loss)\n",
        "        val_losses_resnet.append(val_loss)\n",
        "        models_resnet += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet, \"resnet_models.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6SAi-rywxiV"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    rlct_estimates_sgnht = []\n",
        "    rlct_estimates_sgld = []\n",
        "    for model in models_toy:\n",
        "        rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "            model,\n",
        "            train_loader,\n",
        "            criterion=criterion_toy,\n",
        "            optimizer_kwargs=dict(\n",
        "                lr=1e-7,\n",
        "                diffusion_factor=0.01,\n",
        "                num_samples=len(train_data),\n",
        "            ),\n",
        "            sampling_method=SGNHT,\n",
        "            num_chains=1,\n",
        "            num_draws=400,\n",
        "            num_burnin_steps=0,\n",
        "            num_steps_bw_draws=1,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        rlct_estimate_sgld = estimate_learning_coeff(\n",
        "            model,\n",
        "            train_loader,\n",
        "            criterion=criterion_toy,\n",
        "            optimizer_kwargs=dict(\n",
        "                lr=1e-5,\n",
        "                noise_level=1.0,\n",
        "                elasticity=100.0,\n",
        "                num_samples=len(train_data),\n",
        "                temperature=\"adaptive\",\n",
        "            ),\n",
        "            sampling_method=SGLD,\n",
        "            num_chains=1,\n",
        "            num_draws=400,\n",
        "            num_burnin_steps=0,\n",
        "            num_steps_bw_draws=1,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "        rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "        print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "    # plotting\n",
        "    plot_lambda_vs_epochs(train_losses_toy, val_losses_toy, rlct_estimates_sgnht, rlct_estimates_sgld)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msLVQX2NOgEF"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ______________________    Resnet18 models    ______________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    rlct_estimates_sgnht = []\n",
        "    rlct_estimates_sgld = []\n",
        "    for model in models_resnet:\n",
        "        rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "            model,\n",
        "            train_loader,\n",
        "            criterion=criterion_resnet18,\n",
        "            optimizer_kwargs=dict(\n",
        "                lr=1e-7,\n",
        "                diffusion_factor=0.01,\n",
        "                num_samples=len(train_data),\n",
        "            ),\n",
        "            sampling_method=SGNHT,\n",
        "            num_chains=1,\n",
        "            num_draws=400,\n",
        "            num_burnin_steps=0,\n",
        "            num_steps_bw_draws=1,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        rlct_estimate_sgld = estimate_learning_coeff(\n",
        "            model,\n",
        "            train_loader,\n",
        "            criterion=criterion_resnet18,\n",
        "            optimizer_kwargs=dict(\n",
        "                lr=1e-5,\n",
        "                noise_level=1.0,\n",
        "                elasticity=100.0,\n",
        "                num_samples=len(train_data),\n",
        "                temperature=\"adaptive\",\n",
        "            ),\n",
        "            sampling_method=SGLD,\n",
        "            num_chains=1,\n",
        "            num_draws=400,\n",
        "            num_burnin_steps=0,\n",
        "            num_steps_bw_draws=1,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "        rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "        print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "    # plotting\n",
        "    plot_lambda_vs_epochs(train_losses_resnet, val_losses_resnet, rlct_estimates_sgnht, rlct_estimates_sgld)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oOdiz2RO1J0"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=2$\n",
        "\n",
        "The different sets of labels to explore are: $\\{1, other\\}$ ; $\\{2, other\\}$ ; $\\{4, other\\}$ ; $\\{5, other\\}$ ; $\\{9, other\\}$.\n",
        "`other` cannot be put as a label as it, it needs to be encoded into a integer. In order to relabel as we wish, we simply map the first label/digit of the sets to `1` and all the other to `0`. For example for the set $\\{4,other\\}$ it means that the images representing `4` will be relabeled as `1` and the images representing any of $[0, 1, 2, 3, 5, 6, 7, 8, 9]$ will be relabeled as `0`.\n",
        "\n",
        "* labels modification and data loader\n",
        "* Run for the toy model\n",
        "* Run for the resnet18 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "2AKnZ5jEFArS",
        "outputId": "79f96d00-6363-4de7-c90e-b78d870a4483"
      },
      "outputs": [],
      "source": [
        "# preparing the output directories of XP1\n",
        "dirs = [\"XP1\",\n",
        "        \"XP1/card_2-case_1\",\n",
        "        \"XP1/card_2-case_2\",\"XP1/card_2-case_3\", \"XP1/card_2-case_4\", \"XP1/card_2-case_5\",\n",
        "        \"XP1/card_3-case_1\", \"XP1/card_3-case_2\",\"XP1/card_3-case_3\", \"XP1/card_3-case_4\", \"XP1/card_3-case_5\",\n",
        "        \"XP1/card_4-case_1\", \"XP1/card_4-case_2\",\"XP1/card_4-case_3\", \"XP1/card_4-case_4\",\n",
        "        \"XP1/card_5-case_1\", \"XP1/card_5-case_2\",\"XP1/card_5-case_3\", \"XP1/card_5-case_4\",\n",
        "        \"XP1/card_6-case_1\", \"XP1/card_6-case_2\",\"XP1/card_6-case_3\", \"XP1/card_6-case_4\",\n",
        "        \"XP1/card_8-case_1\", \"XP1/card_8-case_2\",\n",
        "        \"XP1/card_9-case_1\", \"XP1/card_9-case_2\",\n",
        "        \"XP1/card_10-case_1\",\n",
        "        ]\n",
        "\n",
        "for path in dirs:\n",
        "        os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxTOQdAah18j"
      },
      "outputs": [],
      "source": [
        "def load_and_process_data(bs: int, mapping_label_to_encode: dict) -> tuple[DataLoader, DataLoader]:\n",
        "    \"\"\" Loads MNIST dataset, relabel the images of train and test sets\n",
        "\n",
        "    Function load MNIST dataset and performs the relabelling. The loading performs the transformation\n",
        "    necessary to normalize the data distribution.\n",
        "    Before forging the data loaders, the operation of relabelling to execute the experiments\n",
        "    is performed.\n",
        "    Arguments:\n",
        "        bs: batch size, excepting a positive integer\n",
        "        mapping_label_to_encode: mapping between original labels and target labels\n",
        "\n",
        "    Returns:\n",
        "        train_loader, test_loader: data loader of train and test\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    # Load train data\n",
        "    train_data = datasets.MNIST(\"../data\", train=True, transform=transform, download=True)\n",
        "    for old_label, new_label in mapping_label_to_encode.items():\n",
        "        train_data.targets[train_data.targets == old_label] = new_label\n",
        "    print(\"set of labels in train data: \", train_data.targets.unique())\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Load test data\n",
        "    test_data = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
        "    for old_label, new_label in mapping_label_to_encode.items():\n",
        "        test_data.targets[test_data.targets == old_label] = new_label\n",
        "    print(\"set of labels in test data: \", test_data.targets.unique())\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def models_factory(model_type: Literal[\"toy_model\", \"resnet18\"],\n",
        "                   optim_cfg: dict,\n",
        "                   optim_name: Literal['SGD'] = \"SGD\",\n",
        "                   criterion_name: Literal[\"CrossEntropyLoss\"]=\"CrossEntropyLoss\",\n",
        "                   lr: confloat(gt=0, lt=1)=0.005,\n",
        "                   n_epochs: conint(gt=0)=20,\n",
        "                   nb_classes: conint(ge=2, le=10)=10\n",
        "                   ):\n",
        "    \"\"\"Very light factory to handle the model instanciation.\n",
        "\n",
        "    The main purpose of this method is to centralize the models instance\n",
        "    allowing lighter code cells in the following.\n",
        "\n",
        "    Note:\n",
        "        versatility is very limited here, but the idea is to use a common interface to\n",
        "        generate a model withing a collection of possibility\n",
        "\n",
        "    Args:\n",
        "        model_type: name of the model to return\n",
        "        optim_name: optimiser name of the model\n",
        "        optim_cfg: configuration of the optimiser\n",
        "        criterion_name: Loss function associated with the model for training.\n",
        "            Defaults to \"CrossEntropyLoss\".\n",
        "        lr: learning rate. Defaults to 0.005.\n",
        "        n_epochs: number of epochs. Defaults to 20.\n",
        "        nb_classes: number of classes of the task.\n",
        "    \"\"\"\n",
        "    if model_type == \"toy_model\":\n",
        "        model = ToyNet(output_dim=nb_classes).to(DEVICE)\n",
        "    elif model_type == \"resnet18\":\n",
        "        model = resnet18(weights=None).to(DEVICE)\n",
        "\n",
        "        ## changing the last fully connected layer of N neurons, each corresponding to a class.\n",
        "        new_fc_act = nn.Linear(model.fc.in_features, nb_classes)\n",
        "        model.fc = new_fc_act\n",
        "\n",
        "        ## Changing the first conv2d layer to match the input image shape\n",
        "        model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model factory does not handle model_type: '{model_type}'\")\n",
        "\n",
        "    # Loss definition\n",
        "    if criterion_name == \"CrossEntropyLoss\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        ValueError(\"Model factory only handles Cross Entropy Loss.\")\n",
        "\n",
        "    # Optimizer definition\n",
        "    if optim_name == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, **optim_cfg)\n",
        "    else:\n",
        "        ValueError(\"Model factory only handles Cross Entropy Loss.\")\n",
        "\n",
        "    return model, optimizer, criterion\n",
        "\n",
        "\n",
        "def export_loss_acc_to_csv(path: str, train_loss: list[float], test_loss: list[float], train_acc: list[float], test_acc: list[float]):\n",
        "    \"\"\"Save losses and accuracy into csv\n",
        "\n",
        "    Args:\n",
        "        path: path to file to save the data\n",
        "        train_loss: list of the train loss along epochs\n",
        "        test_loss: list of the test loss along epochs\n",
        "        train_acc: list of the train accuracy along epochs\n",
        "        test_acc: list of the test accuracy along epochs\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame().from_dict({\"train_loss\": train_loss,\n",
        "                                   \"test_loss\": test_loss,\n",
        "                                   \"train_accuracy\": train_acc,\n",
        "                                   \"test_accuracy\": test_acc})\n",
        "    df.to_csv(path)\n",
        "\n",
        "def export_rlct_to_csv(path: str, rlct_estimates_sgnht: list[float], rlct_estimates_sgld: list[float]):\n",
        "    \"\"\"Save losses and accuracy into csv\n",
        "\n",
        "    Args:\n",
        "        path: path to file to save the data\n",
        "        rlct_estimates_sgnht: list of rlct estimated with Stochastic Gradient Nose-Hoover Thermostat\n",
        "        rlct_estimates_sgld: list of rlct estimated with Stochastic Gradient Langevin Dynamics\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame().from_dict({\"rlct_estimates_sgnht\": rlct_estimates_sgnht,\n",
        "                                   \"rlct_estimates_sgld\": rlct_estimates_sgld})\n",
        "    df.to_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtQRZcGVFArT"
      },
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "map_label_card_2_1 = {1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_2 = {1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_3 = {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_4 = {1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_5 = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNzAlYirFArT"
      },
      "source": [
        "##### 1.1 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{1, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KUBFtz3QAmP",
        "outputId": "2f00fa07-2d7c-4518-92d3-9050a4b9d7fa"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_1)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# ------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SUC7_eTR3-0",
        "outputId": "161d3fbc-6a96-4cc3-fb99-9b4d4b8176d6"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_1 = []\n",
        "    val_losses_resnet_xp1_1 = []\n",
        "    train_acc_resnet_xp1_1 = []\n",
        "    val_acc_resnet_xp1_1 = []\n",
        "    models_resnet_xp1_1 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_1.append(train_loss)\n",
        "        val_losses_resnet_xp1_1.append(val_loss)\n",
        "        train_acc_resnet_xp1_1.append(train_acc)\n",
        "        val_acc_resnet_xp1_1.append(val_acc)\n",
        "        models_resnet_xp1_1 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_1, \"XP1/card_2-case_1/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_1/resnet_loss_acc.csv\",\n",
        "                       train_loss=train_losses_resnet_xp1_1,\n",
        "                       test_loss=val_losses_resnet_xp1_1,\n",
        "                       train_acc=train_acc_resnet_xp1_1,\n",
        "                       test_acc=val_acc_resnet_xp1_1)\n",
        "\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_1 = []\n",
        "    val_losses_toy_xp1_1 = []\n",
        "    train_acc_toy_xp1_1 = []\n",
        "    val_acc_toy_xp1_1 = []\n",
        "    models_toy_xp1_1 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_1.append(train_loss)\n",
        "        val_losses_toy_xp1_1.append(val_loss)\n",
        "        train_acc_toy_xp1_1.append(train_acc)\n",
        "        val_acc_toy_xp1_1.append(val_acc)\n",
        "        models_toy_xp1_1 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_1, \"XP1/card_2-case_1/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_1/toy_loss_acc.csv\",\n",
        "                       train_loss=train_losses_toy_xp1_1,\n",
        "                       test_loss=val_losses_toy_xp1_1,\n",
        "                       train_acc=train_acc_toy_xp1_1,\n",
        "                       test_acc=val_acc_toy_xp1_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UPb7woG7FArU",
        "outputId": "cabc09af-fcbf-410f-b600-ea3f73e84fdb"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_1:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_1, val_losses_toy_xp1_1, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbdJEc5uGn72"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ______________________    Resnet18 instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_resnet_xp1_1:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_resnet,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_resnet,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_1/resnet_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_resnet_xp1_1, val_losses_resnet_xp1_1, rlct_estimates_sgnht, rlct_estimates_sgld)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBt5-7HhFArU"
      },
      "source": [
        "##### 1.2 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{2, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPq961LZFArV",
        "outputId": "29a07d95-a3f0-49e4-d71c-bfc0fcb4cfcc"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_2)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# ---------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww0LMuWmFArV",
        "outputId": "4d26b065-8c01-4f24-f284-aaba7c09571e"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_2 = []\n",
        "    val_losses_resnet_xp1_2 = []\n",
        "    train_acc_resnet_xp1_2 = []\n",
        "    val_acc_resnet_xp1_2 = []\n",
        "    models_resnet_xp1_2 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_2.append(train_loss)\n",
        "        val_losses_resnet_xp1_2.append(val_loss)\n",
        "        models_resnet_xp1_2 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_2, \"XP1/card_2-case_2/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_2/resnet_loss_acc.csv\",\n",
        "                           train_loss=train_losses_resnet_xp1_2,\n",
        "                           test_loss=val_losses_resnet_xp1_2,\n",
        "                           train_acc=train_acc_resnet_xp1_2,\n",
        "                           test_acc=val_acc_resnet_xp1_2)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_2 = []\n",
        "    val_losses_toy_xp1_2 = []\n",
        "    train_acc_toy_xp1_2 = []\n",
        "    val_acc_toy_xp1_2 = []\n",
        "    models_toy_xp1_2 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_2.append(train_loss)\n",
        "        val_losses_toy_xp1_2.append(val_loss)\n",
        "        train_acc_toy_xp1_2.append(train_acc)\n",
        "        val_acc_toy_xp1_2.append(val_acc)\n",
        "        models_toy_xp1_2 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_2, \"XP1/card_2-case_2/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_2/toy_loss_acc.csv\",\n",
        "                           train_loss=train_losses_toy_xp1_2,\n",
        "                           test_loss=val_losses_toy_xp1_2,\n",
        "                           train_acc=train_acc_toy_xp1_2,\n",
        "                           test_acc=val_acc_toy_xp1_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KmSEo2ukLjt4",
        "outputId": "c65c617b-7504-4a37-befe-b52c26435edd"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_2:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_2, val_losses_toy_xp1_2, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4Ny5A1LFArV"
      },
      "source": [
        "##### 1.3 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{4, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-1WtZtjFArV",
        "outputId": "e150ffd4-16cc-4c4c-deca-0845a48aa449"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_3)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMQN8LlOFArW",
        "outputId": "e626ae88-a500-4c81-db80-5e9616fe49b0"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_3 = []\n",
        "    val_losses_resnet_xp1_3 = []\n",
        "    train_acc_resnet_xp1_3 = []\n",
        "    val_acc_resnet_xp1_3 = []\n",
        "    models_resnet_xp1_3 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_3.append(train_loss)\n",
        "        val_losses_resnet_xp1_3.append(val_loss)\n",
        "        train_acc_resnet_xp1_3.append(train_acc)\n",
        "        val_acc_resnet_xp1_3.append(val_acc)\n",
        "        models_resnet_xp1_3 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_3, \"XP1/card_2-case_3/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_3/resnet_loss_acc.csv\",\n",
        "                           train_loss=train_losses_resnet_xp1_3,\n",
        "                           test_loss=val_losses_resnet_xp1_3,\n",
        "                           train_acc=train_acc_resnet_xp1_3,\n",
        "                           test_acc=val_acc_resnet_xp1_3)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_3 = []\n",
        "    val_losses_toy_xp1_3 = []\n",
        "    train_acc_toy_xp1_3 = []\n",
        "    val_acc_toy_xp1_3 = []\n",
        "    models_toy_xp1_3 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_3.append(train_loss)\n",
        "        val_losses_toy_xp1_3.append(val_loss)\n",
        "        train_acc_toy_xp1_3.append(train_acc)\n",
        "        val_acc_toy_xp1_3.append(val_acc)\n",
        "        models_toy_xp1_3 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_3, \"XP1/card_2-case_3/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_3/toy_loss_acc.csv\",\n",
        "                           train_loss=train_losses_toy_xp1_3,\n",
        "                           test_loss=val_losses_toy_xp1_3,\n",
        "                           train_acc=train_acc_toy_xp1_3,\n",
        "                           test_acc=val_acc_toy_xp1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fs3UbQzOP1GZ",
        "outputId": "e6d7867c-835a-4a48-9692-6e245277ec27"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_3:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_3/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_3, val_losses_toy_xp1_3, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srQgIb7QFArW"
      },
      "source": [
        "##### 1.4 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{5, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdQFwiklFArW",
        "outputId": "23739eb8-68ef-4ebc-c6b4-73827f398a50"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_4)\n",
        "# ---------------------------------------------------\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# ---------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqu4TlUNFArW",
        "outputId": "1bea75f5-8ac9-4cf0-8f9b-6d84e4d2208d"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_4 = []\n",
        "    val_losses_resnet_xp1_4 = []\n",
        "    train_acc_resnet_xp1_4 = []\n",
        "    val_acc_resnet_xp1_4 = []\n",
        "    models_resnet_xp1_4 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_4.append(train_loss)\n",
        "        val_losses_resnet_xp1_4.append(val_loss)\n",
        "        train_acc_resnet_xp1_4.append(train_acc)\n",
        "        val_acc_resnet_xp1_4.append(val_acc)\n",
        "        models_resnet_xp1_4 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_4, \"XP1/card_2-case_4/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_4/resnet_loss_acc.csv\",\n",
        "                           train_loss=train_losses_resnet_xp1_4,\n",
        "                           test_loss=val_losses_resnet_xp1_4,\n",
        "                           train_acc=train_acc_resnet_xp1_4,\n",
        "                           test_acc=val_acc_resnet_xp1_4)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_4 = []\n",
        "    val_losses_toy_xp1_4 = []\n",
        "    train_acc_toy_xp1_4 = []\n",
        "    val_acc_toy_xp1_4 = []\n",
        "    models_toy_xp1_4 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_4.append(train_loss)\n",
        "        val_losses_toy_xp1_4.append(val_loss)\n",
        "        train_acc_toy_xp1_4.append(train_acc)\n",
        "        val_acc_toy_xp1_4.append(val_acc)\n",
        "        models_toy_xp1_4 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_4, \"XP1/card_2-case_4/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_4/toy_loss_acc.csv\",\n",
        "                           train_loss=train_losses_toy_xp1_4,\n",
        "                           test_loss=val_losses_toy_xp1_4,\n",
        "                           train_acc=train_acc_toy_xp1_4,\n",
        "                           test_acc=val_acc_toy_xp1_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZWvG7XU3SV1O",
        "outputId": "3083185e-b469-40a8-c738-7389a43870b3"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_4:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_4/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_4, val_losses_toy_xp1_4, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8-I5oWxFArW"
      },
      "source": [
        "##### 1.5 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oretTh7TFArW",
        "outputId": "992726bf-5055-4cf5-ede9-f5836af00fe1"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_5)\n",
        "# --------------------------------------------------\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# --------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDCnK3GUFArX",
        "outputId": "a9d9db62-872a-4d25-c2f6-e5487fcfb8b2"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_5 = []\n",
        "    val_losses_resnet_xp1_5 = []\n",
        "    train_acc_resnet_xp1_5 = []\n",
        "    val_acc_resnet_xp1_5 = []\n",
        "    models_resnet_xp1_5 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_5.append(train_loss)\n",
        "        val_losses_resnet_xp1_5.append(val_loss)\n",
        "        train_acc_resnet_xp1_5.append(train_acc)\n",
        "        val_acc_resnet_xp1_5.append(val_acc)\n",
        "        models_resnet_xp1_5 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_5, \"XP1/card_2-case_5/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_5/resnet_loss_acc.csv\",\n",
        "                           train_loss=train_losses_resnet_xp1_5,\n",
        "                           test_loss=val_losses_resnet_xp1_5,\n",
        "                           train_acc=train_acc_resnet_xp1_5,\n",
        "                           test_acc=val_acc_resnet_xp1_5)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_5 = []\n",
        "    val_losses_toy_xp1_5 = []\n",
        "    train_acc_toy_xp1_5 = []\n",
        "    val_acc_toy_xp1_5 = []\n",
        "    models_toy_xp1_5 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_5.append(train_loss)\n",
        "        val_losses_toy_xp1_5.append(val_loss)\n",
        "        train_acc_toy_xp1_5.append(train_acc)\n",
        "        val_acc_toy_xp1_5.append(val_acc)\n",
        "        models_toy_xp1_5 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_5, \"XP1/card_2-case_5/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_2-case_5/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_5,\n",
        "                            test_loss=val_losses_toy_xp1_5,\n",
        "                            train_acc=train_acc_toy_xp1_5,\n",
        "                            test_acc=val_acc_toy_xp1_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d31XzaNLZaZ3",
        "outputId": "6723b6d6-2031-4f62-ee2b-5f023ffb344d"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_5:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_2-case_5/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_5, val_losses_toy_xp1_5, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8a86rSZO-Xf"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=3$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 3 classes\n",
        "* Resnet18 model for 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9nT6IYnFArX"
      },
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# [{2, 6, other} ; {3, 6, other} ; {0, 4, other} ; {8, 9, other} ; {5, 7, other}]\n",
        "map_label_card_3_1 = {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 2, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_2 = {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 2, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_3 = {0: 1, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_4 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 2}\n",
        "map_label_card_3_5 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 2, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vym4k47WFArX"
      },
      "source": [
        "##### 2.1 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{2, 6, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3yII5toFArY",
        "outputId": "a57d0840-960f-43f6-bd80-75cd77b23abe"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3D1-BUaFArY",
        "outputId": "829e9a51-2792-4996-bea8-1832e72046c9"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_6 = []\n",
        "    val_losses_resnet_xp1_6 = []\n",
        "    train_acc_resnet_xp1_6 = []\n",
        "    val_acc_resnet_xp1_6 = []\n",
        "    models_resnet_xp1_6 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_6.append(train_loss)\n",
        "        val_losses_resnet_xp1_6.append(val_loss)\n",
        "        train_acc_resnet_xp1_6.append(train_acc)\n",
        "        val_acc_resnet_xp1_6.append(val_acc)\n",
        "        models_resnet_xp1_6 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_6, \"XP1/card_3-case_1/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_1/resnet_loss_acc.csv\",\n",
        "                            train_loss=train_losses_resnet_xp1_6,\n",
        "                            test_loss=val_losses_resnet_xp1_6,\n",
        "                            train_acc=train_acc_resnet_xp1_6,\n",
        "                            test_acc=val_acc_resnet_xp1_6)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_6 = []\n",
        "    val_losses_toy_xp1_6 = []\n",
        "    train_acc_toy_xp1_6 = []\n",
        "    val_acc_toy_xp1_6 = []\n",
        "    models_toy_xp1_6 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_6.append(train_loss)\n",
        "        val_losses_toy_xp1_6.append(val_loss)\n",
        "        train_acc_toy_xp1_6.append(train_acc)\n",
        "        val_acc_toy_xp1_6.append(val_acc)\n",
        "        models_toy_xp1_6 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_6, \"XP1/card_3-case_1/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_1/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_6,\n",
        "                                test_loss=val_losses_toy_xp1_6,\n",
        "                                train_acc=train_acc_toy_xp1_6,\n",
        "                                test_acc=val_acc_toy_xp1_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2a-bMdIjeyup",
        "outputId": "d8276d80-9b82-4f3d-ad13-a29da36a2874"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_6:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_3-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_6, val_losses_toy_xp1_6, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2UBObH1FArY"
      },
      "source": [
        "##### 2.2 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{3, 6, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPIf-s61FArY",
        "outputId": "bfcba020-50a1-4cbc-9ab2-c67be3ec36a9"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDk6WeWbFArZ",
        "outputId": "19c51e6e-fe25-4f67-9d80-7f194afc0bed"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_7 = []\n",
        "    val_losses_resnet_xp1_7 = []\n",
        "    train_acc_resnet_xp1_7 = []\n",
        "    val_acc_resnet_xp1_7 = []\n",
        "    models_resnet_xp1_7 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_7.append(train_loss)\n",
        "        val_losses_resnet_xp1_7.append(val_loss)\n",
        "        train_acc_resnet_xp1_7.append(train_acc)\n",
        "        val_acc_resnet_xp1_7.append(val_acc)\n",
        "        models_resnet_xp1_7 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_7, \"XP1/card_3-case_2/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_2/resnet_loss_acc.csv\",\n",
        "                                train_loss=train_losses_resnet_xp1_7,\n",
        "                                test_loss=val_losses_resnet_xp1_7,\n",
        "                                train_acc=train_acc_resnet_xp1_7,\n",
        "                                test_acc=val_acc_resnet_xp1_7)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_7 = []\n",
        "    val_losses_toy_xp1_7 = []\n",
        "    train_acc_toy_xp1_7 = []\n",
        "    val_acc_toy_xp1_7 = []\n",
        "    models_toy_xp1_7 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_7.append(train_loss)\n",
        "        val_losses_toy_xp1_7.append(val_loss)\n",
        "        train_acc_toy_xp1_7.append(train_acc)\n",
        "        val_acc_toy_xp1_7.append(val_acc)\n",
        "        models_toy_xp1_7 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_7, \"XP1/card_3-case_2/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_2/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_7,\n",
        "                                test_loss=val_losses_toy_xp1_7,\n",
        "                                train_acc=train_acc_toy_xp1_7,\n",
        "                                test_acc=val_acc_toy_xp1_7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K8H7XU9xjU3J",
        "outputId": "14afc80e-8372-4ffb-cc85-f482b517445e"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_7:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_3-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_7, val_losses_toy_xp1_7, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP07D9TmFArZ"
      },
      "source": [
        "##### 2.3 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{0, 4, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ-RAeNZFArZ",
        "outputId": "4dba02ae-8be4-4383-b91e-6091a937fba5"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_3)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFLewkkaFAra",
        "outputId": "4ec7ec67-50ae-4c1c-b5f0-1638caf1cb85"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_8 = []\n",
        "    val_losses_resnet_xp1_8 = []\n",
        "    train_acc_resnet_xp1_8 = []\n",
        "    val_acc_resnet_xp1_8 = []\n",
        "    models_resnet_xp1_8 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_8.append(train_loss)\n",
        "        val_losses_resnet_xp1_8.append(val_loss)\n",
        "        train_acc_resnet_xp1_8.append(train_acc)\n",
        "        val_acc_resnet_xp1_8.append(val_acc)\n",
        "        models_resnet_xp1_8 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_8, \"XP1/card_3-case_3/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_3/resnet_loss_acc.csv\",\n",
        "                                train_loss=train_losses_resnet_xp1_8,\n",
        "                                test_loss=val_losses_resnet_xp1_8,\n",
        "                                train_acc=train_acc_resnet_xp1_8,\n",
        "                                test_acc=val_acc_resnet_xp1_8)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_8 = []\n",
        "    val_losses_toy_xp1_8 = []\n",
        "    train_acc_toy_xp1_8 = []\n",
        "    val_acc_toy_xp1_8 = []\n",
        "    models_toy_xp1_8 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_8.append(train_loss)\n",
        "        val_losses_toy_xp1_8.append(val_loss)\n",
        "        train_acc_toy_xp1_8.append(train_acc)\n",
        "        val_acc_toy_xp1_8.append(val_acc)\n",
        "        models_toy_xp1_8 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_8, \"XP1/card_3-case_3/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_3/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_8,\n",
        "                                test_loss=val_losses_toy_xp1_8,\n",
        "                                train_acc=train_acc_toy_xp1_8,\n",
        "                                test_acc=val_acc_toy_xp1_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fr0BiwoujawK",
        "outputId": "85f726c2-2858-4b85-9edd-f0464f00857b"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_8:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_3-case_3/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_8, val_losses_toy_xp1_8, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlCM12NfFAra"
      },
      "source": [
        "##### 2.4 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{8, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-mE3ULpFAra",
        "outputId": "bb528bb8-ab50-400b-feb2-3ca5b0028c8a"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_4)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m09zS_aCFArb",
        "outputId": "75b653df-c554-4d82-e99f-0973b25374db"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_9 = []\n",
        "    val_losses_resnet_xp1_9 = []\n",
        "    train_acc_resnet_xp1_9 = []\n",
        "    val_acc_resnet_xp1_9 = []\n",
        "    models_resnet_xp1_9 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_9.append(train_loss)\n",
        "        val_losses_resnet_xp1_9.append(val_loss)\n",
        "        train_acc_resnet_xp1_9.append(train_acc)\n",
        "        val_acc_resnet_xp1_9.append(val_acc)\n",
        "        models_resnet_xp1_9 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_9, \"XP1/card_3-case_4/resnet_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_4/resnet_loss_acc.csv\",\n",
        "                                train_loss=train_losses_resnet_xp1_9,\n",
        "                                test_loss=val_losses_resnet_xp1_9,\n",
        "                                train_acc=train_acc_resnet_xp1_9,\n",
        "                                test_acc=val_acc_resnet_xp1_9)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_9 = []\n",
        "    val_losses_toy_xp1_9 = []\n",
        "    train_acc_toy_xp1_9 = []\n",
        "    val_acc_toy_xp1_9 = []\n",
        "    models_toy_xp1_9 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_9.append(train_loss)\n",
        "        val_losses_toy_xp1_9.append(val_loss)\n",
        "        train_acc_toy_xp1_9.append(train_acc)\n",
        "        val_acc_toy_xp1_9.append(val_acc)\n",
        "        models_toy_xp1_9 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_9, \"XP1/card_3-case_4/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_4/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_9,\n",
        "                                test_loss=val_losses_toy_xp1_9,\n",
        "                                train_acc=train_acc_toy_xp1_9,\n",
        "                                test_acc=val_acc_toy_xp1_9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "edlf1YbMqJ3s",
        "outputId": "8fdbeca9-c7c5-4068-9657-f15edddece7d"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_9:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_3-case_4/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_9, val_losses_toy_xp1_9, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuYH5t9wFArb"
      },
      "source": [
        "##### 2.5 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{5, 7, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMytFEjSFArb",
        "outputId": "f7f47ee8-77c2-493d-9dd8-5705f7e7935d"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_5)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyp7xPoyFArc",
        "outputId": "2ec42c99-a4e3-4206-91b7-142de3ddd393"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_10 = []\n",
        "    val_losses_resnet_xp1_10 = []\n",
        "    models_resnet_xp1_10 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_10.append(train_loss)\n",
        "        val_losses_resnet_xp1_10.append(val_loss)\n",
        "        models_resnet_xp1_10 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_10, \"XP1/card_3-case_5/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_10 = []\n",
        "    val_losses_toy_xp1_10 = []\n",
        "    train_acc_toy_xp1_10 = []\n",
        "    val_acc_toy_xp1_10 = []\n",
        "    models_toy_xp1_10 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_10.append(train_loss)\n",
        "        val_losses_toy_xp1_10.append(val_loss)\n",
        "        train_acc_toy_xp1_10.append(train_acc)\n",
        "        val_acc_toy_xp1_10.append(val_acc)\n",
        "        models_toy_xp1_10 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_10, \"XP1/card_3-case_5/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_3-case_5/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_10,\n",
        "                                test_loss=val_losses_toy_xp1_10,\n",
        "                                train_acc=train_acc_toy_xp1_10,\n",
        "                                test_acc=val_acc_toy_xp1_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xeFJ63X-sS3y",
        "outputId": "c8717661-dbb4-4fcb-8da6-d8dd7dc5e0d4"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_10:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_3-case_5/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_10, val_losses_toy_xp1_10, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALax802SO-SS"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=4$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 4 classes\n",
        "* Resnet18 model for 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHHkYi2UQBkE"
      },
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# [{0, 5, 6, other} ; {6, 7, 9, other} ; {2, 3, 5, other} ; {0, 1, 4, other}]\n",
        "map_label_card_4_1 = {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 2, 6: 3, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_2 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 2, 8: 0, 9: 3}\n",
        "map_label_card_4_3 = {0: 0, 1: 0, 2: 1, 3: 2, 4: 0, 5: 3, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_4 = {0: 1, 1: 2, 2: 0, 3: 0, 4: 3, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5mw-zIXFArd"
      },
      "source": [
        "##### 3.1 XP1 - labels set $\\mathcal{Card} = 4$ - $\\mathcal{L}abels=\\{0, 5, 6, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeXT4ChtFArd",
        "outputId": "67fc730d-b0e4-4ad8-f030-6bdee810b3e1"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_4_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 4\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa1OmKS4FArd",
        "outputId": "78a9b5de-57f3-4af1-ad92-38603d4176b9"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_11 = []\n",
        "    val_losses_resnet_xp1_11 = []\n",
        "    models_resnet_xp1_11 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_11.append(train_loss)\n",
        "        val_losses_resnet_xp1_11.append(val_loss)\n",
        "        models_resnet_xp1_11 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_11, \"XP1/card_4-case_1/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_11 = []\n",
        "    val_losses_toy_xp1_11 = []\n",
        "    train_acc_toy_xp1_11 = []\n",
        "    val_acc_toy_xp1_11 = []\n",
        "    models_toy_xp1_11 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_11.append(train_loss)\n",
        "        val_losses_toy_xp1_11.append(val_loss)\n",
        "        train_acc_toy_xp1_11.append(train_acc)\n",
        "        val_acc_toy_xp1_11.append(val_acc)\n",
        "        models_toy_xp1_11 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_11, \"XP1/card_4-case_1/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_4-case_1/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_11,\n",
        "                                test_loss=val_losses_toy_xp1_11,\n",
        "                                train_acc=train_acc_toy_xp1_11,\n",
        "                                test_acc=val_acc_toy_xp1_11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ES0G5h_ws1_Q",
        "outputId": "9462afca-13ee-480d-9ca5-3f8384afbff4"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_11:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_4-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_11, val_losses_toy_xp1_11, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EUoKurbFArd"
      },
      "source": [
        "##### 3.2 XP1 - labels set $\\mathcal{Card} = 4$ - $\\mathcal{L}abels=\\{6, 7, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MZENJHbFArd",
        "outputId": "95b95650-0a68-4537-f0db-4ff6e613dbae"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_4_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 4\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAJ-nD-bFAre",
        "outputId": "d181d3c6-9564-405a-9edc-854fef91bbb1"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_12 = []\n",
        "    val_losses_resnet_xp1_12 = []\n",
        "    models_resnet_xp1_12 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_12.append(train_loss)\n",
        "        val_losses_resnet_xp1_12.append(val_loss)\n",
        "        models_resnet_xp1_12 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_12, \"XP1/card_4-case_2/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_12 = []\n",
        "    val_losses_toy_xp1_12 = []\n",
        "    train_acc_toy_xp1_12 = []\n",
        "    val_acc_toy_xp1_12 = []\n",
        "    models_toy_xp1_12 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_12.append(train_loss)\n",
        "        val_losses_toy_xp1_12.append(val_loss)\n",
        "        train_acc_toy_xp1_12.append(train_acc)\n",
        "        val_acc_toy_xp1_12.append(val_acc)\n",
        "        models_toy_xp1_12 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_12, \"XP1/card_4-case_2/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_4-case_2/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_12,\n",
        "                                test_loss=val_losses_toy_xp1_12,\n",
        "                                train_acc=train_acc_toy_xp1_12,\n",
        "                                test_acc=val_acc_toy_xp1_12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iBlZUgAVtVdu",
        "outputId": "462caed5-9234-4437-d92f-8ee4339ab614"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_12:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_4-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_12, val_losses_toy_xp1_12, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4H5W9zLFAre"
      },
      "source": [
        "##### 3.3 XP1 - labels set $\\mathcal{Card} = 4$ - $\\mathcal{L}abels=\\{2, 3, 5, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4OK-2uZFAre",
        "outputId": "f6b24045-7989-4978-8749-9b49a50c19c3"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_4_3)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 4\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVwMyrtJFAre",
        "outputId": "58fa8e23-de4d-49ae-d68c-7cd794ab6b0f"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_13 = []\n",
        "    val_losses_resnet_xp1_13 = []\n",
        "    models_resnet_xp1_13 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_13.append(train_loss)\n",
        "        val_losses_resnet_xp1_13.append(val_loss)\n",
        "        models_resnet_xp1_13 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_13, \"XP1/card_4-case_3/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_13 = []\n",
        "    val_losses_toy_xp1_13 = []\n",
        "    train_acc_toy_xp1_13 = []\n",
        "    val_acc_toy_xp1_13 = []\n",
        "    models_toy_xp1_13 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_13.append(train_loss)\n",
        "        val_losses_toy_xp1_13.append(val_loss)\n",
        "        train_acc_toy_xp1_13.append(train_acc)\n",
        "        val_acc_toy_xp1_13.append(val_acc)\n",
        "        models_toy_xp1_13 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_13, \"XP1/card_4-case_3/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_4-case_3/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_13,\n",
        "                                test_loss=val_losses_toy_xp1_13,\n",
        "                                train_acc=train_acc_toy_xp1_13,\n",
        "                                test_acc=val_acc_toy_xp1_13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMcL-lu0t3-R"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_13:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_4-case_3/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_13, val_losses_toy_xp1_13, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb0EF8S4FAre"
      },
      "source": [
        "##### 3.4 XP1 - labels set $\\mathcal{Card} = 4$ - $\\mathcal{L}abels=\\{0, 1, 4, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XigXxa4wFAre"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_4_4)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 4\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_LqY4McFArf",
        "outputId": "a69113ea-03a6-436d-bd81-42b86c338c4b"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_14 = []\n",
        "    val_losses_resnet_xp1_14 = []\n",
        "    models_resnet_xp1_14 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_14.append(train_loss)\n",
        "        val_losses_resnet_xp1_14.append(val_loss)\n",
        "        models_resnet_xp1_14 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_14, \"XP1/card_4-case_4/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_14 = []\n",
        "    val_losses_toy_xp1_14 = []\n",
        "    train_acc_toy_xp1_14 = []\n",
        "    val_acc_toy_xp1_14 = []\n",
        "    models_toy_xp1_14 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_14.append(train_loss)\n",
        "        val_losses_toy_xp1_14.append(val_loss)\n",
        "        train_acc_toy_xp1_14.append(train_acc)\n",
        "        val_acc_toy_xp1_14.append(val_acc)\n",
        "        models_toy_xp1_14 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_14, \"XP1/card_4-case_4/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_4-case_4/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_14,\n",
        "                                test_loss=val_losses_toy_xp1_14,\n",
        "                                train_acc=train_acc_toy_xp1_14,\n",
        "                                test_acc=val_acc_toy_xp1_14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0SuDMJY0uoxD",
        "outputId": "2fa4572c-765d-4fe7-ac53-fa88f014b752"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_14:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_4-case_4/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_14, val_losses_toy_xp1_14, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuC3UmWFO-JA"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=5$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 5 classes\n",
        "* Resnet18 model for 5 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd2SL9FkFArf"
      },
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# {0, 1, 4, 5, other} ; {0, 1, 7, 8, other} ; {4, 5, 7, 9, other} ; {2, 3, 6, 7, other}\n",
        "map_label_card_5_1 = {0: 1, 1: 2, 2: 0, 3: 0, 4: 3, 5: 4, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_5_2 = {0: 1, 1: 2, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 3, 8: 4, 9: 0}\n",
        "map_label_card_5_3 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 0, 7: 3, 8: 0, 9: 4}\n",
        "map_label_card_5_4 = {0: 0, 1: 0, 2: 1, 3: 2, 4: 0, 5: 0, 6: 3, 7: 4, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T86bU9QXFArf"
      },
      "source": [
        "##### 4.1 XP1 - labels set $\\mathcal{Card} = 5$ - $\\mathcal{L}abels=\\{0, 1, 4, 5, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4wn64jiFArf"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_5_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 5\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XLjjmoWFArg"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_15 = []\n",
        "    val_losses_resnet_xp1_15 = []\n",
        "    models_resnet_xp1_15 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_15.append(train_loss)\n",
        "        val_losses_resnet_xp1_15.append(val_loss)\n",
        "        models_resnet_xp1_15 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_15, \"XP1/card_5-case_1/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_15 = []\n",
        "    val_losses_toy_xp1_15 = []\n",
        "    train_acc_toy_xp1_15 = []\n",
        "    val_acc_toy_xp1_15 = []\n",
        "    models_toy_xp1_15 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_15.append(train_loss)\n",
        "        val_losses_toy_xp1_15.append(val_loss)\n",
        "        train_acc_toy_xp1_15.append(train_acc)\n",
        "        val_acc_toy_xp1_15.append(val_acc)\n",
        "        models_toy_xp1_15 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_15, \"XP1/card_5-case_1/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_5-case_1/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_15,\n",
        "                                test_loss=val_losses_toy_xp1_15,\n",
        "                                train_acc=train_acc_toy_xp1_15,\n",
        "                                test_acc=val_acc_toy_xp1_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh7Yjumxv4AR",
        "outputId": "4c1c3a04-83f5-405b-9044-54bc0e8c0e93"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_15:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_5-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_15, val_losses_toy_xp1_15, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSxkPwnwFArg"
      },
      "source": [
        "##### 4.2 XP1 - labels set $\\mathcal{Card} = 5$ - $\\mathcal{L}abels=\\{0, 1, 7, 8, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnLcSNvQFArg"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_5_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 5\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRx4ohM9FArg"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_16 = []\n",
        "    val_losses_resnet_xp1_16 = []\n",
        "    models_resnet_xp1_16 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_16.append(train_loss)\n",
        "        val_losses_resnet_xp1_16.append(val_loss)\n",
        "        models_resnet_xp1_16 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_16, \"XP1/card_5-case_2/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_16 = []\n",
        "    val_losses_toy_xp1_16 = []\n",
        "    train_acc_toy_xp1_16 = []\n",
        "    val_acc_toy_xp1_16 = []\n",
        "    models_toy_xp1_16 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_16.append(train_loss)\n",
        "        val_losses_toy_xp1_16.append(val_loss)\n",
        "        train_acc_toy_xp1_16.append(train_acc)\n",
        "        val_acc_toy_xp1_16.append(val_acc)\n",
        "        models_toy_xp1_16 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_16, \"XP1/card_5-case_2/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_5-case_2/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_16,\n",
        "                                test_loss=val_losses_toy_xp1_16,\n",
        "                                train_acc=train_acc_toy_xp1_16,\n",
        "                                test_acc=val_acc_toy_xp1_16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_16:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_5-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_16, val_losses_toy_xp1_16, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGgmphaKFArg"
      },
      "source": [
        "##### 4.3 XP1 - labels set $\\mathcal{Card} = 5$ - $\\mathcal{L}abels=\\{4, 5, 7, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee9eel-BFArh"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_5_3)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 5\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4pMsZ-dFArh"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_17 = []\n",
        "    val_losses_resnet_xp1_17 = []\n",
        "    models_resnet_xp1_17 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_17.append(train_loss)\n",
        "        val_losses_resnet_xp1_17.append(val_loss)\n",
        "        models_resnet_xp1_17 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_17, \"XP1/card_5-case_3/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_17 = []\n",
        "    val_losses_toy_xp1_17 = []\n",
        "    train_acc_toy_xp1_17 = []\n",
        "    val_acc_toy_xp1_17 = []\n",
        "    models_toy_xp1_17 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_17.append(train_loss)\n",
        "        val_losses_toy_xp1_17.append(val_loss)\n",
        "        train_acc_toy_xp1_17.append(train_acc)\n",
        "        val_acc_toy_xp1_17.append(val_acc)\n",
        "        models_toy_xp1_17 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_17, \"XP1/card_5-case_3/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_5-case_3/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_17,\n",
        "                                test_loss=val_losses_toy_xp1_17,\n",
        "                                train_acc=train_acc_toy_xp1_17,\n",
        "                                test_acc=val_acc_toy_xp1_17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_17:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_5-case_3/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_17, val_losses_toy_xp1_17, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hSuwW8NFArh"
      },
      "source": [
        "##### 4.4 XP1 - labels set $\\mathcal{Card} = 5$ - $\\mathcal{L}abels=\\{2, 3, 6, 7, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1SWz_WBFArh"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_5_4)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 5\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKI3ECW7FAri"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_18 = []\n",
        "    val_losses_resnet_xp1_18 = []\n",
        "    models_resnet_xp1_18 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_18.append(train_loss)\n",
        "        val_losses_resnet_xp1_18.append(val_loss)\n",
        "        models_resnet_xp1_18 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_18, \"XP1/card_5-case_4/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_18 = []\n",
        "    val_losses_toy_xp1_18 = []\n",
        "    train_acc_toy_xp1_18 = []\n",
        "    val_acc_toy_xp1_18 = []\n",
        "    models_toy_xp1_18 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_18.append(train_loss)\n",
        "        val_losses_toy_xp1_18.append(val_loss)\n",
        "        train_acc_toy_xp1_18.append(train_acc)\n",
        "        val_acc_toy_xp1_18.append(val_acc)\n",
        "        models_toy_xp1_18 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_18, \"XP1/card_5-case_4/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_5-case_4/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_18,\n",
        "                                test_loss=val_losses_toy_xp1_18,\n",
        "                                train_acc=train_acc_toy_xp1_18,\n",
        "                                test_acc=val_acc_toy_xp1_18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9nTnDMpQB9b"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_18:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_5-case_4/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_18, val_losses_toy_xp1_18, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings and runs label sets ð¶ððð($\\mathcal{L}$ððððð )=6\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 6 classes\n",
        "* Resnet18 model for 6 classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# {1, 2, 3, 6, 9, other} ; {3, 4, 7, 8, 9, other} ; {1, 3, 5, 7, 8, other} ; {0, 2, 4, 6, 7, other}\n",
        "map_label_card_6_1 = {0: 0, 1: 1, 2: 2, 3: 3, 4: 0, 5: 0, 6: 4, 7: 0, 8: 0, 9: 5}\n",
        "map_label_card_6_2 = {0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 0, 6: 0, 7: 3, 8: 4, 9: 5}\n",
        "map_label_card_6_3 = {0: 0, 1: 1, 2: 0, 3: 2, 4: 0, 5: 3, 6: 0, 7: 4, 8: 5, 9: 0}\n",
        "map_label_card_6_4 = {0: 1, 1: 0, 2: 2, 3: 0, 4: 3, 5: 0, 6: 4, 7: 5, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5.1 XP1 - labels set $\\mathcal{Card} = 6$ - $\\mathcal{L}abels=\\{1, 2, 3, 6, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_6_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 6\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_19 = []\n",
        "    val_losses_resnet_xp1_19 = []\n",
        "    models_resnet_xp1_19 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_19.append(train_loss)\n",
        "        val_losses_resnet_xp1_19.append(val_loss)\n",
        "        models_resnet_xp1_19 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_19, \"XP1/card_6-case_1/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_19 = []\n",
        "    val_losses_toy_xp1_19 = []\n",
        "    train_acc_toy_xp1_19 = []\n",
        "    val_acc_toy_xp1_19 = []\n",
        "    models_toy_xp1_19 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_19.append(train_loss)\n",
        "        val_losses_toy_xp1_19.append(val_loss)\n",
        "        train_acc_toy_xp1_19.append(train_acc)\n",
        "        val_acc_toy_xp1_19.append(val_acc)\n",
        "        models_toy_xp1_19 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_19, \"XP1/card_6-case_1/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_6-case_1/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_19,\n",
        "                                test_loss=val_losses_toy_xp1_19,\n",
        "                                train_acc=train_acc_toy_xp1_19,\n",
        "                                test_acc=val_acc_toy_xp1_19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_19:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_6-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_19, val_losses_toy_xp1_19, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5.2 XP1 - labels set $\\mathcal{Card} = 6$ - $\\mathcal{L}abels=\\{3, 4, 7, 8, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_6_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 6\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_20 = []\n",
        "    val_losses_resnet_xp1_20 = []\n",
        "    models_resnet_xp1_20 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_20.append(train_loss)\n",
        "        val_losses_resnet_xp1_20.append(val_loss)\n",
        "        models_resnet_xp1_20 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_20, \"XP1/card_6-case_2/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_20 = []\n",
        "    val_losses_toy_xp1_20 = []\n",
        "    train_acc_toy_xp1_20 = []\n",
        "    val_acc_toy_xp1_20 = []\n",
        "    models_toy_xp1_20 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_20.append(train_loss)\n",
        "        val_losses_toy_xp1_20.append(val_loss)\n",
        "        train_acc_toy_xp1_20.append(train_acc)\n",
        "        val_acc_toy_xp1_20.append(val_acc)\n",
        "        models_toy_xp1_20 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_20, \"XP1/card_6-case_2/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_6-case_2/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_20,\n",
        "                                test_loss=val_losses_toy_xp1_20,\n",
        "                                train_acc=train_acc_toy_xp1_20,\n",
        "                                test_acc=val_acc_toy_xp1_20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_20:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_6-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_20, val_losses_toy_xp1_20, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5.3 XP1 - labels set $\\mathcal{Card} = 6$ - $\\mathcal{L}abels=\\{1, 3, 5, 7, 8, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_6_3)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 6\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_21 = []\n",
        "    val_losses_resnet_xp1_21 = []\n",
        "    models_resnet_xp1_21 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_21.append(train_loss)\n",
        "        val_losses_resnet_xp1_21.append(val_loss)\n",
        "        models_resnet_xp1_21 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_21, \"XP1/card_6-case_3/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_21 = []\n",
        "    val_losses_toy_xp1_21 = []\n",
        "    train_acc_toy_xp1_21 = []\n",
        "    val_acc_toy_xp1_21 = []\n",
        "    models_toy_xp1_21 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_21.append(train_loss)\n",
        "        val_losses_toy_xp1_21.append(val_loss)\n",
        "        train_acc_toy_xp1_21.append(train_acc)\n",
        "        val_acc_toy_xp1_21.append(val_acc)\n",
        "        models_toy_xp1_21 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_21, \"XP1/card_6-case_3/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_6-case_3/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_21,\n",
        "                                test_loss=val_losses_toy_xp1_21,\n",
        "                                train_acc=train_acc_toy_xp1_21,\n",
        "                                test_acc=val_acc_toy_xp1_21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_21:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_6-case_3/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_21, val_losses_toy_xp1_21, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5.4 XP1 - labels set $\\mathcal{Card} = 6$ - $\\mathcal{L}abels=\\{0, 2, 4, 6, 7, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_6_4)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 6\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_resnet:\n",
        "    train_losses_resnet_xp1_22 = []\n",
        "    val_losses_resnet_xp1_22 = []\n",
        "    models_resnet_xp1_22 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_resnet18,\n",
        "                                        optimizer_resnet18,\n",
        "                                        criterion_resnet18,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_resnet18,\n",
        "                                    criterion_resnet18,\n",
        "                                    test_loader)\n",
        "        train_losses_resnet_xp1_22.append(train_loss)\n",
        "        val_losses_resnet_xp1_22.append(val_loss)\n",
        "        models_resnet_xp1_22 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_resnet_xp1_22, \"XP1/card_6-case_4/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_22 = []\n",
        "    val_losses_toy_xp1_22 = []\n",
        "    train_acc_toy_xp1_22 = []\n",
        "    val_acc_toy_xp1_22 = []\n",
        "    models_toy_xp1_22 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_22.append(train_loss)\n",
        "        val_losses_toy_xp1_22.append(val_loss)\n",
        "        train_acc_toy_xp1_22.append(train_acc)\n",
        "        val_acc_toy_xp1_22.append(val_acc)\n",
        "        models_toy_xp1_22 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "    torch.save(models_toy_xp1_22, \"XP1/card_6-case_4/toy_models.pth\")\n",
        "    export_loss_acc_to_csv(path=\"XP1/card_6-case_4/toy_loss_acc.csv\",\n",
        "                                train_loss=train_losses_toy_xp1_22,\n",
        "                                test_loss=val_losses_toy_xp1_22,\n",
        "                                train_acc=train_acc_toy_xp1_22,\n",
        "                                test_acc=val_acc_toy_xp1_22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_22:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_6-case_4/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_22, val_losses_toy_xp1_22, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TViZYvtfPDkQ"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=10$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 10 classes\n",
        "* Resnet18 model for 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiFPlfl4QCup"
      },
      "outputs": [],
      "source": [
        "# Depending of the run type, cuda or cpu mode is defined\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --------------------------------------------\n",
        "N_CLASSES = 10 # for the 10 class digits of MNIST\n",
        "lr = 0.005\n",
        "n_epochs = 20\n",
        "# --------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    model_resnet18 = resnet18(weights=None).to(DEVICE)\n",
        "\n",
        "    ## changing the last fully connected layer of N neurons, each corresponding to a class.\n",
        "    new_fc_act = nn.Linear(model_resnet18.fc.in_features, N_CLASSES)\n",
        "    model_resnet18.fc = new_fc_act\n",
        "\n",
        "    ## Changing the first conv2d layer to match the input image shape\n",
        "    model_resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    # Loss and optimizer definition\n",
        "    criterion_resnet18 = nn.CrossEntropyLoss()\n",
        "    optimizer_resnet18 = optim.SGD(model_resnet18.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    # Initialize model, loss, optimizer and sgld sampler\n",
        "    model_toy = ToyNet().to(DEVICE)\n",
        "    criterion_toy = nn.CrossEntropyLoss()\n",
        "    optimizer_toy = optim.SGD(model_toy.parameters(), lr=lr, momentum=0.9, nesterov=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_23 = []\n",
        "    val_losses_toy_xp1_23 = []\n",
        "    train_acc_toy_xp1_23 = []\n",
        "    val_acc_toy_xp1_23 = []\n",
        "    models_toy_xp1_23 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_23.append(train_loss)\n",
        "        val_losses_toy_xp1_23.append(val_loss)\n",
        "        train_acc_toy_xp1_23.append(train_acc)\n",
        "        val_acc_toy_xp1_23.append(val_acc)\n",
        "        models_toy_xp1_23 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_23, \"XP1/card_10-case_1/toy_models.pth\")\n",
        "export_loss_acc_to_csv(path=\"XP1/card_10-case_1/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_23,\n",
        "                            test_loss=val_losses_toy_xp1_23,\n",
        "                            train_acc=train_acc_toy_xp1_23,\n",
        "                            test_acc=val_acc_toy_xp1_23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_23:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_10-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_23, val_losses_toy_xp1_23, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=8$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 8 classes\n",
        "* Resnet18 model for 8 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# {1, 2, 3, 6, 9, other} ; {3, 4, 7, 8, 9, other} ; {1, 3, 5, 7, 8, other} ; {0, 2, 4, 6, 7, other}\n",
        "map_label_card_8_1 = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 0, 9: 0}\n",
        "map_label_card_8_2 = {0: 1, 1: 2, 2: 3, 3: 0, 4: 0, 5: 0, 6: 5, 7: 6, 8: 7, 9: 0}\n",
        "\n",
        "# BEWARE !! Due to the method of relabelling their is a corner case not well handle leading to less than 8 labels for second mapping\n",
        "# It has been excluded from the report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_8_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 8\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_24 = []\n",
        "    val_losses_toy_xp1_24 = []\n",
        "    train_acc_toy_xp1_24 = []\n",
        "    val_acc_toy_xp1_24 = []\n",
        "    models_toy_xp1_24 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_24.append(train_loss)\n",
        "        val_losses_toy_xp1_24.append(val_loss)\n",
        "        train_acc_toy_xp1_24.append(train_acc)\n",
        "        val_acc_toy_xp1_24.append(val_acc)\n",
        "        models_toy_xp1_24 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_24, \"XP1/card_8-case_1/toy_models.pth\")\n",
        "export_loss_acc_to_csv(path=\"XP1/card_8-case_1/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_24,\n",
        "                            test_loss=val_losses_toy_xp1_24,\n",
        "                            train_acc=train_acc_toy_xp1_24,\n",
        "                            test_acc=val_acc_toy_xp1_24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_24:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_8-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_24, val_losses_toy_xp1_24, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_8_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 8\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_25 = []\n",
        "    val_losses_toy_xp1_25 = []\n",
        "    train_acc_toy_xp1_25 = []\n",
        "    val_acc_toy_xp1_25 = []\n",
        "    models_toy_xp1_25 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_25.append(train_loss)\n",
        "        val_losses_toy_xp1_25.append(val_loss)\n",
        "        train_acc_toy_xp1_25.append(train_acc)\n",
        "        val_acc_toy_xp1_25.append(val_acc)\n",
        "        models_toy_xp1_25 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_25, \"XP1/card_8-case_2/toy_models.pth\")\n",
        "export_loss_acc_to_csv(path=\"XP1/card_8-case_2/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_25,\n",
        "                            test_loss=val_losses_toy_xp1_25,\n",
        "                            train_acc=train_acc_toy_xp1_25,\n",
        "                            test_acc=val_acc_toy_xp1_25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_25:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_8-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_25, val_losses_toy_xp1_25, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=9$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 9 classes\n",
        "* Resnet18 model for 9 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# {1, 2, 3, 6, 9, other} ; {3, 4, 7, 8, 9, other} ; {1, 3, 5, 7, 8, other} ; {0, 2, 4, 6, 7, other}\n",
        "map_label_card_9_1 = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 0}\n",
        "map_label_card_9_2 = {0: 1, 1: 2, 2: 3, 3: 0, 4: 0, 5: 0, 6: 5, 7: 6, 8: 7, 9: 8}\n",
        "\n",
        "# BEWARE !! Due to the method of relabelling their is a corner case not well handle leading to less than 9 labels for second mapping\n",
        "# It has been excluded from the report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_9_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 9\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_26 = []\n",
        "    val_losses_toy_xp1_26 = []\n",
        "    train_acc_toy_xp1_26 = []\n",
        "    val_acc_toy_xp1_26 = []\n",
        "    models_toy_xp1_26 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_26.append(train_loss)\n",
        "        val_losses_toy_xp1_26.append(val_loss)\n",
        "        train_acc_toy_xp1_26.append(train_acc)\n",
        "        val_acc_toy_xp1_26.append(val_acc)\n",
        "        models_toy_xp1_26 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_26, \"XP1/card_9-case_1/toy_models.pth\")\n",
        "export_loss_acc_to_csv(path=\"XP1/card_9-case_1/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_26,\n",
        "                            test_loss=val_losses_toy_xp1_26,\n",
        "                            train_acc=train_acc_toy_xp1_26,\n",
        "                            test_acc=val_acc_toy_xp1_26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_26:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_9-case_1/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_26, val_losses_toy_xp1_26, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_9_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 9\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "if run_toy_model:\n",
        "    model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                            optim_cfg=dict_optim_cfg,\n",
        "                                                            nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "if run_resnet:\n",
        "    models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                    optim_cfg=dict_optim_cfg,\n",
        "                                                                    nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "if run_toy_model:\n",
        "    train_losses_toy_xp1_27 = []\n",
        "    val_losses_toy_xp1_27 = []\n",
        "    train_acc_toy_xp1_27 = []\n",
        "    val_acc_toy_xp1_27 = []\n",
        "    models_toy_xp1_27 = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_step(model_toy,\n",
        "                                        optimizer_toy,\n",
        "                                        criterion_toy,\n",
        "                                        train_loader)\n",
        "        val_loss, val_acc = val_step(model_toy,\n",
        "                                    criterion_toy,\n",
        "                                    test_loader)\n",
        "        train_losses_toy_xp1_27.append(train_loss)\n",
        "        val_losses_toy_xp1_27.append(val_loss)\n",
        "        train_acc_toy_xp1_27.append(train_acc)\n",
        "        val_acc_toy_xp1_27.append(val_acc)\n",
        "        models_toy_xp1_27 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "        print_step_report(epoch=epoch,\n",
        "                        train_loss=train_loss,\n",
        "                        val_loss=val_loss,\n",
        "                        train_acc=train_acc,\n",
        "                        val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_27, \"XP1/card_9-case_2/toy_models.pth\")\n",
        "export_loss_acc_to_csv(path=\"XP1/card_9-case_2/toy_loss_acc.csv\",\n",
        "                            train_loss=train_losses_toy_xp1_27,\n",
        "                            test_loss=val_losses_toy_xp1_27,\n",
        "                            train_acc=train_acc_toy_xp1_27,\n",
        "                            test_acc=val_acc_toy_xp1_27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_27:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)\n",
        "\n",
        "# plotting\n",
        "export_rlct_to_csv(\"XP1/card_9-case_2/toy_rlct_estimated.csv\",\n",
        "                    rlct_estimates_sgnht=rlct_estimates_sgnht,\n",
        "                    rlct_estimates_sgld=rlct_estimates_sgld)\n",
        "plot_lambda_vs_epochs(train_losses_toy_xp1_27, val_losses_toy_xp1_27, rlct_estimates_sgnht, rlct_estimates_sgld)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5naegrOpGP"
      },
      "source": [
        "## Displays Î» ð£ð  $\\mathcal{L}$ððððð "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58TfSEILwxiV"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\", color=PRIMARY)\n",
        "ax1.plot(train_losses, label=\"Train Loss\", color=PRIMARY)\n",
        "ax1.plot(test_losses, label=\"Test Loss\", color=PRIMARY_LIGHT)\n",
        "ax1.tick_params(axis=\"y\", labelcolor=PRIMARY)\n",
        "ax1.legend(loc=\"lower left\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(r\"Local Learning Coefficient, $\\hat \\lambda$\", color=SECONDARY)\n",
        "ax2.plot(rlct_estimates_sgnht, label=\"SGNHT\", color=SECONDARY)\n",
        "ax2.plot(rlct_estimates_sgld, label=\"SGLD\", color=SECONDARY_LIGHT)\n",
        "ax2.tick_params(axis=\"y\", labelcolor=SECONDARY)\n",
        "ax2.legend(loc=\"center right\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eNzAlYirFArT",
        "PBt5-7HhFArU",
        "s4Ny5A1LFArV",
        "srQgIb7QFArW",
        "f8-I5oWxFArW"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
