{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giIyPcmTPUiM"
      },
      "source": [
        "# SERIMATS Application\n",
        "\n",
        "\n",
        "|           |                |\n",
        "| : ----- : | :------------: |\n",
        "| Candidate | Matthieu David |\n",
        "| stream    | developmental interpretability |\n",
        "| subject   | [task variability](https://devinterp.com/projects/task-variability) |\n",
        "\n",
        "\n",
        "\n",
        "This notebook is inspired from the notebook [RLCT Estimation of MNIST](https://colab.research.google.com/github/timaeus-research/devinterp/blob/main/examples/mnist.ipynb) with large change to fit my submission.\n",
        "\n",
        "\n",
        "---\n",
        "## RLCT Estimation of MNIST\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]()\n",
        "\n",
        "This Jupyter Notebook aims to reproduce the results of Lau et al. (2023) by measuring the Real Log Canonical Threshold (RLCT) for a small 2-layer ReLU model (about 1M parameters) trained on the MNIST dataset. It uses both Stochastic Gradient Nose-Hoover Thermostat (SGNHT) and Stochastic Gradient Langevin Dynamics (SGLD) as sampling methods.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents:\n",
        "* packages installation\n",
        "* Import for the all notebook\n",
        "* Method definitions\n",
        "* Experiments 1 (XP1): Impact of the number of classes\n",
        "    * Toy model and Resnet18 instances\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 2$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 3$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 4$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 5$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 6$\n",
        "    * Settings and runs label sets $Card(\\mathcal{L}abels) = 10$\n",
        "* Displays $Î»\\ vs\\ \\mathcal{L}abels$\n",
        "* Experiments 2 (XP2): Impact of the data diversity\n",
        "* Experiments 3 (XP3): Impact of the number of classes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7SG-MJmEAb"
      },
      "source": [
        "## Package installation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qveJHrTCwxiR",
        "outputId": "7803b1f5-f09c-4223-d42b-0f31282d0033"
      },
      "outputs": [],
      "source": [
        "%pip install devinterp matplotlib seaborn torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndBsAQfymIpo"
      },
      "source": [
        "## Import for all the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQsK8RymwxiS"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from pydantic.types import confloat, conint\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from typing import Literal\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from devinterp.optim.sgld import SGLD\n",
        "from devinterp.optim.sgnht import SGNHT\n",
        "\n",
        "PRIMARY, SECONDARY, TERTIARY = sns.color_palette(\"muted\")[:3]\n",
        "PRIMARY_LIGHT, SECONDARY_LIGHT, TERTIARY_LIGHT = sns.color_palette(\"pastel\")[:3]\n",
        "sns.set_theme(\"paper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1LHW2tDmPef"
      },
      "source": [
        "## Method definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hznyDuvMoCM4"
      },
      "source": [
        "#### Class of the Toy model:\n",
        "The toy model corresponds to the initial model used in the notebook RLCT Estimation of MNIST (rewrite a little for lisibility). This model is made of 2 linear layers, each activations being a ReLU function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LqUSR-nwxiS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the toy neural network\n",
        "class OriginalToyNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes=[1024, 1024],\n",
        "        input_dim=28 * 28,\n",
        "        output_dim=10,\n",
        "        activation=F.relu,\n",
        "        with_bias=True,\n",
        "    ):\n",
        "        super(OriginalToyNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.layer_sizes = [input_dim] + hidden_layer_sizes + [output_dim]\n",
        "        self.activation = activation\n",
        "        self.with_bias = with_bias\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(self.layer_sizes) - 1):\n",
        "            dim_in, dim_out = self.layer_sizes[i : i + 2]\n",
        "            self.layers.append(nn.Linear(dim_in, dim_out, bias=self.with_bias).float())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x\n",
        "\n",
        "# Define the toy neural network\n",
        "class ToyNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes=[1024, 1024],\n",
        "        input_dim=28 * 28,\n",
        "        output_dim=10,\n",
        "        with_bias=True,\n",
        "    ):\n",
        "        super(ToyNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.with_bias = with_bias\n",
        "        self.layer_sizes = [input_dim] + hidden_layer_sizes + [output_dim]\n",
        "\n",
        "        # First basic block = Linear + ReLU activation\n",
        "        self.fc_1 = nn.Linear(in_features=input_dim, out_features=1024, bias=self.with_bias)\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        # 2nd basic block = Linear + ReLU activation\n",
        "        self.fc_2 = nn.Linear(in_features=1024, out_features=1024, bias=self.with_bias)\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        # Last Fully Connected layer:\n",
        "        self.fc_3 = nn.Linear(in_features=1024, out_features=output_dim, bias=self.with_bias)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "\n",
        "        x = self.fc_1(x)\n",
        "        x = self.relu_1(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = self.relu_2(x)\n",
        "        x = self.relu_2(x)\n",
        "\n",
        "        x = self.fc_3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzAGhKntn_yy"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
        "    \"Original train_one_epoch method from MNIST notebook of timaeus/devinterp\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for data, target in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(DEVICE))\n",
        "        loss = criterion(output, target.to(DEVICE))\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    \"Original evaluate method from MNIST notebook of timaeus/devinterp\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(DEVICE))\n",
        "            loss = criterion(output, target.to(DEVICE))\n",
        "            test_loss += loss.item()\n",
        "    return test_loss / len(test_loader)\n",
        "\n",
        "\n",
        "def train_step(model, optimizer, criterion, train_set):\n",
        "    model.train()\n",
        "    # model.to(DEVICE)\n",
        "\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    i = 0\n",
        "    prog_bar = tqdm(train_set, desc=f\"\\ttrain_loss: {train_loss:0.2f} -- train_acc: {train_acc:0.2f} %\")\n",
        "    for x, y in prog_bar:\n",
        "        # Stating variables\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        output = model(x) # Forward step\n",
        "        loss = criterion(output, y) # Loss step\n",
        "\n",
        "        # Backward step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accuracy\n",
        "        top_p, prediction = output.topk(1, dim=1)\n",
        "        equals = (prediction == y.view(*prediction.shape))\n",
        "\n",
        "        prog_bar.set_description(f\"\\ttrain_loss: {train_loss / len(train_set) :0.5f} -- train_acc: {100 * train_acc / len(train_set) :0.2f} %\")\n",
        "        # Saving data\n",
        "        train_loss += loss.item()\n",
        "        train_acc += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return train_loss / len(train_set), train_acc / len(train_set)\n",
        "\n",
        "\n",
        "def val_step(model, criterion, val_set):\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "\n",
        "    model.eval()\n",
        "    # model.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(val_set):\n",
        "            # Stating variables\n",
        "            images = x.to(DEVICE)\n",
        "            labels = y.to(DEVICE)\n",
        "\n",
        "            output = model(images) # Forward step\n",
        "\n",
        "            loss = criterion(output, labels) # Loss step\n",
        "\n",
        "            # Accuracy\n",
        "            top_p, prediction = output.topk(1, dim=1)\n",
        "            equals = (prediction == labels.view(*prediction.shape))\n",
        "\n",
        "            # Saving data\n",
        "            val_loss += loss.item()\n",
        "            val_acc += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    return val_loss / len(val_set), val_acc / len(val_set)\n",
        "\n",
        "def print_step_report(epoch:int, train_loss: float, val_loss: float, train_acc: float, val_acc: float):\n",
        "    print(f\"Epoch {epoch+1}:\\n\" \\\n",
        "          f\"Train Loss: {train_loss:.5f}\" \\\n",
        "          f\"-- Val Loss: {val_loss:.5f}\" \\\n",
        "          f\"-- Train Acc: {train_acc:0.2f}\" \\\n",
        "          f\"-- Val Acc: {val_acc:0.2f}\")\n",
        "    \n",
        "def plot_lambda_vs_epochs(train_losses, test_losses, rlct_estimates_sgnht, rlct_estimates_sgld):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\", color=PRIMARY)\n",
        "    ax1.plot(train_losses, label=\"Train Loss\", color=PRIMARY)\n",
        "    ax1.plot(test_losses, label=\"Test Loss\", color=PRIMARY_LIGHT)\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=PRIMARY)\n",
        "    ax1.legend(loc=\"lower left\")\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel(r\"Local Learning Coefficient, $\\hat \\lambda$\", color=SECONDARY)\n",
        "    ax2.plot(rlct_estimates_sgnht, label=\"SGNHT\", color=SECONDARY)\n",
        "    ax2.plot(rlct_estimates_sgld, label=\"SGLD\", color=SECONDARY_LIGHT)\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=SECONDARY)\n",
        "    ax2.legend(loc=\"center right\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoVkYJvmmYVK"
      },
      "source": [
        "## Experiments 1 (XP1): Impact of the number of classes\n",
        "\n",
        "This section contains all the experiments about the XP1 detailled in the application report [here](link)\n",
        "\n",
        "First basic code cells are given the dataset MNIST and basics training with the Toy model and Resnet18 are reported. The readers can explore the core process without modifying the code for the actual experiment.\n",
        "\n",
        "Secondly each sub experiments possess a dedicated sub section , new data loaders are generated, where the labels are rewritten to performed the experiment with the dedicated label set cardinality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ib7yhNmglL"
      },
      "source": [
        "### MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbOo-km8mEmF"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data\n",
        "## definition of the transformation to apply to dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.244, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_data = datasets.MNIST(\"../data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\"../data\", train=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbCKghWUmsk7"
      },
      "source": [
        "### Toy model and Resnet18 instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coSwenPswxiT"
      },
      "outputs": [],
      "source": [
        "# Depending of the run type, cuda or cpu mode is defined\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --------------------------------------------\n",
        "N_CLASSES = 10 # for the 10 class digits of MNIST\n",
        "lr = 0.005\n",
        "n_epochs = 20\n",
        "# --------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "model_resnet18 = resnet18(weights=None).to(DEVICE)\n",
        "\n",
        "## changing the last fully connected layer of N neurons, each corresponding to a class.\n",
        "new_fc_act = nn.Linear(model_resnet18.fc.in_features, N_CLASSES)\n",
        "model_resnet18.fc = new_fc_act\n",
        "\n",
        "## Changing the first conv2d layer to match the input image shape\n",
        "model_resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "# Loss and optimizer definition\n",
        "criterion_resnet18 = nn.CrossEntropyLoss()\n",
        "optimizer_resnet18 = optim.SGD(model_resnet18.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "model_toy = ToyNet().to(DEVICE)\n",
        "criterion_toy = nn.CrossEntropyLoss()\n",
        "optimizer_toy = optim.SGD(model_toy.parameters(), lr=lr, momentum=0.9, nesterov=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sDUnyjFrErX",
        "outputId": "681ad1d0-5649-4e67-a44c-676384cec4fe"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_toy = []\n",
        "val_losses_toy = []\n",
        "models_toy = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy.append(train_loss)\n",
        "    val_losses_toy.append(val_loss)\n",
        "    models_toy += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy, \"toy_models.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "KGRlwa01wxiU",
        "outputId": "5f81561f-7983-48f3-a5a6-100b2ee0a351"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet = []\n",
        "val_losses_resnet = []\n",
        "models_resnet = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet.append(train_loss)\n",
        "    val_losses_resnet.append(val_loss)\n",
        "    models_resnet += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet, \"resnet_models.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6SAi-rywxiV",
        "outputId": "2e2b79bf-9f23-4246-eb6e-047a7dbc5473"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "from devinterp.slt import estimate_learning_coeff\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_lambda_vs_epochs(train_losses_toy, val_losses_toy, rlct_estimates_sgnht, rlct_estimates_sgld)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msLVQX2NOgEF"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ______________________    Resnet18 models    ______________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "from devinterp.slt import estimate_learning_coeff\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_resnet:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_resnet18,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_resnet18,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oOdiz2RO1J0"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=2$\n",
        "\n",
        "The different sets of labels to explore are: $\\{1, other\\}$ ; $\\{2, other\\}$ ; $\\{4, other\\}$ ; $\\{5, other\\}$ ; $\\{9, other\\}$.\n",
        "`other` cannot be put as a label as it, it needs to be encoded into a integer. In order to relabel as we wish, we simply map the first label/digit of the sets to `1` and all the other to `0`. For example for the set $\\{4,other\\}$ it means that the images representing `4` will be relabeled as `1` and the images representing any of $[0, 1, 2, 3, 5, 6, 7, 8, 9]$ will be relabeled as `0`.\n",
        "\n",
        "* labels modification and data loader\n",
        "* Run for the toy model\n",
        "* Run for the resnet18 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preparing the output directories of XP1\n",
        "dirs = [\"XP1\",\n",
        "        \"XP1/card_2-case_1\", \"XP1/card_2-case_2\",\"XP1/card_2-case_3\", \"XP1/card_2-case_4\", \"XP1/card_2-case_5\",\n",
        "        \"XP1/card_3-case_1\", \"XP1/card_3-case_2\",\"XP1/card_3-case_3\", \"XP1/card_3-case_4\", \"XP1/card_3-case_5\",\n",
        "        \"XP1/card_4-case_1\", \"XP1/card_4-case_2\",\"XP1/card_4-case_3\", \"XP1/card_4-case_4\", \"XP1/card_4-case_5\",\n",
        "        \"XP1/card_5-case_1\", \"XP1/card_5-case_2\",\"XP1/card_5-case_3\", \"XP1/card_5-case_4\", \"XP1/card_5-case_5\",\n",
        "        \"XP1/card_10-case_1\", \"XP1/card_10-case_2\",\"XP1/card_10-case_3\", \"XP1/card_10-case_4\", \"XP1/card_10-case_5\"]\n",
        "\n",
        "for path in dirs:\n",
        "        os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxTOQdAah18j"
      },
      "outputs": [],
      "source": [
        "def load_and_process_data(bs: int, mapping_label_to_encode: dict) -> tuple[DataLoader, DataLoader]:\n",
        "    \"\"\" Loads MNIST dataset, relabel the images of train and test sets\n",
        "\n",
        "    Function load MNIST dataset and performs the relabelling. The loading performs the transformation\n",
        "    necessary to normalize the data distribution.\n",
        "    Before forging the data loaders, the operation of relabelling to execute the experiments\n",
        "    is performed.\n",
        "    Arguments:\n",
        "        bs: batch size, excepting a positive integer\n",
        "        mapping_label_to_encode: mapping between original labels and target labels\n",
        "\n",
        "    Returns:\n",
        "        train_loader, test_loader: data loader of train and test\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    # Load train data\n",
        "    train_data = datasets.MNIST(\"../data\", train=True, transform=transform, download=True)\n",
        "    for old_label, new_label in mapping_label_to_encode.items():\n",
        "        train_data.targets[train_data.targets == old_label] = new_label\n",
        "    print(\"set of labels in train data: \", train_data.targets.unique())\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Load test data\n",
        "    test_data = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
        "    for old_label, new_label in mapping_label_to_encode.items():\n",
        "        test_data.targets[test_data.targets == old_label] = new_label\n",
        "    print(\"set of labels in test data: \", test_data.targets.unique())\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def models_factory(model_type: Literal[\"toy_model\", \"resnet18\"],\n",
        "                   optim_cfg: dict,\n",
        "                   optim_name: Literal['SGD'] = \"SGD\",\n",
        "                   criterion_name: Literal[\"CrossEntropyLoss\"]=\"CrossEntropyLoss\",\n",
        "                   lr: confloat(gt=0, lt=1)=0.005,\n",
        "                   n_epochs: conint(gt=0)=20,\n",
        "                   nb_classes: conint(ge=2, le=10)=10\n",
        "                   ):\n",
        "    \"\"\"Very light factory to handle the model instanciation.\n",
        "\n",
        "    The main purpose of this method is to centralize the models instance\n",
        "    allowing lighter code cells in the following.\n",
        "\n",
        "    Note:\n",
        "        versatility is very limited here, but the idea is to use a common interface to\n",
        "        generate a model withing a collection of possibility\n",
        "\n",
        "    Args:\n",
        "        model_type: name of the model to return\n",
        "        optim_name: optimiser name of the model\n",
        "        optim_cfg: configuration of the optimiser\n",
        "        criterion_name: Loss function associated with the model for training.\n",
        "            Defaults to \"CrossEntropyLoss\".\n",
        "        lr: learning rate. Defaults to 0.005.\n",
        "        n_epochs: number of epochs. Defaults to 20.\n",
        "        nb_classes: number of classes of the task.\n",
        "    \"\"\"\n",
        "    if model_type == \"toy_model\":\n",
        "        model_toy = ToyNet(output_dim=2).to(DEVICE)\n",
        "    elif model_type == \"resnet18\":\n",
        "        model_resnet18 = resnet18(weights=None).to(DEVICE)\n",
        "\n",
        "        ## changing the last fully connected layer of N neurons, each corresponding to a class.\n",
        "        new_fc_act = nn.Linear(model_resnet18.fc.in_features, N_CLASSES)\n",
        "        model_resnet18.fc = new_fc_act\n",
        "\n",
        "        ## Changing the first conv2d layer to match the input image shape\n",
        "        model_resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model factory does not handle model_type: '{model_type}'\")\n",
        "        \n",
        "    # Loss definition\n",
        "    if criterion_name == \"CrossEntropyLoss\":\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        ValueError(\"Model factory only handles Cross Entropy Loss.\")\n",
        "    \n",
        "    # Optimizer definition\n",
        "    if optim_name == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, **optim_cfg)\n",
        "    else:\n",
        "        ValueError(\"Model factory only handles Cross Entropy Loss.\")\n",
        "\n",
        "    return model, optimizer, criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "map_label_card_2_1 = {1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_2 = {1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_3 = {1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_4 = {1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_2_5 = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.1 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{1, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KUBFtz3QAmP",
        "outputId": "29aa077e-88f3-439f-913a-3c2eb47e7e3d"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_1)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "\n",
        "model_toy, optimizer_toy, criterion_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, optimizer_resnet, criterion_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SUC7_eTR3-0",
        "outputId": "e171c7f0-331f-4279-de7e-30b6f1294514"
      },
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "# train_losses_resnet_xp1_1 = []\n",
        "# val_losses_resnet_xp1_1 = []\n",
        "# models_resnet_xp1_1 = []\n",
        "# for epoch in range(n_epochs):\n",
        "#     train_loss, train_acc = train_step(model_resnet18,\n",
        "#                                        optimizer_resnet18,\n",
        "#                                        criterion_resnet18,\n",
        "#                                        train_loader)\n",
        "#     val_loss, val_acc = val_step(model_resnet18,\n",
        "#                                   criterion_resnet18,\n",
        "#                                   test_loader)\n",
        "#     train_losses_resnet_xp1_1.append(train_loss)\n",
        "#     val_losses_resnet_xp1_1.append(val_loss)\n",
        "#     models_resnet_xp1_1 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "#     print_step_report(epoch=epoch,\n",
        "#                       train_loss=train_loss,\n",
        "#                       val_loss=val_loss,\n",
        "#                       train_acc=train_acc,\n",
        "#                       val_acc=val_acc)\n",
        "\n",
        "# torch.save(models_resnet_xp1_1, \"XP1/card_2-case_1/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_1 = []\n",
        "val_losses_toy_xp1_1 = []\n",
        "models_toy_xp1_1 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_1.append(train_loss)\n",
        "    val_losses_toy_xp1_1.append(val_loss)\n",
        "    models_toy_xp1_1 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_1, \"XP1/card_2-case_1/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy Model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "from devinterp.slt import estimate_learning_coeff\n",
        "\n",
        "rlct_estimates_sgnht = []\n",
        "rlct_estimates_sgld = []\n",
        "for model in models_toy_xp1_1:\n",
        "    rlct_estimate_sgnht = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-7,\n",
        "            diffusion_factor=0.01,\n",
        "            num_samples=len(train_data),\n",
        "        ),\n",
        "        sampling_method=SGNHT,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimate_sgld = estimate_learning_coeff(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion=criterion_toy,\n",
        "        optimizer_kwargs=dict(\n",
        "            lr=1e-5,\n",
        "            noise_level=1.0,\n",
        "            elasticity=100.0,\n",
        "            num_samples=len(train_data),\n",
        "            temperature=\"adaptive\",\n",
        "        ),\n",
        "        sampling_method=SGLD,\n",
        "        num_chains=1,\n",
        "        num_draws=400,\n",
        "        num_burnin_steps=0,\n",
        "        num_steps_bw_draws=1,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "    rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
        "    rlct_estimates_sgld += [rlct_estimate_sgld]\n",
        "    print(rlct_estimate_sgld, rlct_estimate_sgnht)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_lambda_vs_epochs(train_losses_toy_xp1_1, val_losses_toy_xp1_1, rlct_estimates_sgnht, rlct_estimates_sgld)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.2 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{2, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_2)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_2 = []\n",
        "val_losses_resnet_xp1_2 = []\n",
        "models_resnet_xp1_2 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_2.append(train_loss)\n",
        "    val_losses_resnet_xp1_2.append(val_loss)\n",
        "    models_resnet_xp1_2 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_2, \"XP1/card_2-case_2/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_2 = []\n",
        "val_losses_toy_xp1_2 = []\n",
        "models_toy_xp1_2 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_2.append(train_loss)\n",
        "    val_losses_toy_xp1_2.append(val_loss)\n",
        "    models_toy_xp1_2 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_2, \"XP1/card_2-case_2/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.3 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{4, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_3)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_3 = []\n",
        "val_losses_resnet_xp1_3 = []\n",
        "models_resnet_xp1_3 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_3.append(train_loss)\n",
        "    val_losses_resnet_xp1_3.append(val_loss)\n",
        "    models_resnet_xp1_3 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_3, \"XP1/card_2-case_3/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_3 = []\n",
        "val_losses_toy_xp1_3 = []\n",
        "models_toy_xp1_3 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_3.append(train_loss)\n",
        "    val_losses_toy_xp1_3.append(val_loss)\n",
        "    models_toy_xp1_3 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_3, \"XP1/card_2-case_3/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.4 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{5, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_4)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_4 = []\n",
        "val_losses_resnet_xp1_4 = []\n",
        "models_resnet_xp1_4 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_4.append(train_loss)\n",
        "    val_losses_resnet_xp1_4.append(val_loss)\n",
        "    models_resnet_xp1_4 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_4, \"XP1/card_2-case_4/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_4 = []\n",
        "val_losses_toy_xp1_4 = []\n",
        "models_toy_xp1_4 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_4.append(train_loss)\n",
        "    val_losses_toy_xp1_4.append(val_loss)\n",
        "    models_toy_xp1_4 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_4, \"XP1/card_2-case_4/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.5 XP1 - labels set $\\mathcal{Card} = 2$ - $\\mathcal{L}abels=\\{9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## definition of the transformation to apply to dataset\n",
        "\n",
        "\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_2_5)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 2\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_5 = []\n",
        "val_losses_resnet_xp1_5 = []\n",
        "models_resnet_xp1_5 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_5.append(train_loss)\n",
        "    val_losses_resnet_xp1_5.append(val_loss)\n",
        "    models_resnet_xp1_5 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_5, \"XP1/card_2-case_5/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_5 = []\n",
        "val_losses_toy_xp1_5 = []\n",
        "models_toy_xp1_5 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_5.append(train_loss)\n",
        "    val_losses_toy_xp1_5.append(val_loss)\n",
        "    models_toy_xp1_5 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_5, \"XP1/card_2-case_5/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8a86rSZO-Xf"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=3$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 3 classes\n",
        "* Resnet18 model for 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# [{2, 6, other} ; {3, 6, other} ; {0, 4, other} ; {8, 9, other} ; {5, 7, other}]\n",
        "map_label_card_3_1 = {0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 2, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_2 = {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 2, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_3 = {0: 1, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_3_4 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 2}\n",
        "map_label_card_3_5 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 0, 7: 2, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.1 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{2, 6, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_1)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_6 = []\n",
        "val_losses_resnet_xp1_6 = []\n",
        "models_resnet_xp1_6 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_6.append(train_loss)\n",
        "    val_losses_resnet_xp1_6.append(val_loss)\n",
        "    models_resnet_xp1_6 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_6, \"XP1/card_3-case_1/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_6 = []\n",
        "val_losses_toy_xp1_6 = []\n",
        "models_toy_xp1_6 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_6.append(train_loss)\n",
        "    val_losses_toy_xp1_6.append(val_loss)\n",
        "    models_toy_xp1_6 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_6, \"XP1/card_3-case_1/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.2 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{3, 6, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_2)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_7 = []\n",
        "val_losses_resnet_xp1_7 = []\n",
        "models_resnet_xp1_7 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_7.append(train_loss)\n",
        "    val_losses_resnet_xp1_7.append(val_loss)\n",
        "    models_resnet_xp1_7 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_7, \"XP1/card_3-case_2/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_7 = []\n",
        "val_losses_toy_xp1_7 = []\n",
        "models_toy_xp1_7 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_7.append(train_loss)\n",
        "    val_losses_toy_xp1_7.append(val_loss)\n",
        "    models_toy_xp1_7 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_7, \"XP1/card_3-case_2/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.3 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{0, 4, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_3)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_8 = []\n",
        "val_losses_resnet_xp1_8 = []\n",
        "models_resnet_xp1_8 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_8.append(train_loss)\n",
        "    val_losses_resnet_xp1_8.append(val_loss)\n",
        "    models_resnet_xp1_8 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_8, \"XP1/card_3-case_3/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_8 = []\n",
        "val_losses_toy_xp1_8 = []\n",
        "models_toy_xp1_8 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_8.append(train_loss)\n",
        "    val_losses_toy_xp1_8.append(val_loss)\n",
        "    models_toy_xp1_8 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_8, \"XP1/card_3-case_3/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.4 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{8, 9, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_4)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_9 = []\n",
        "val_losses_resnet_xp1_9 = []\n",
        "models_resnet_xp1_9 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_9.append(train_loss)\n",
        "    val_losses_resnet_xp1_9.append(val_loss)\n",
        "    models_resnet_xp1_9 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_9, \"XP1/card_3-case_4/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_9 = []\n",
        "val_losses_toy_xp1_9 = []\n",
        "models_toy_xp1_9 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_9.append(train_loss)\n",
        "    val_losses_toy_xp1_9.append(val_loss)\n",
        "    models_toy_xp1_9 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_9, \"XP1/card_3-case_4/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.5 XP1 - labels set $\\mathcal{Card} = 3$ - $\\mathcal{L}abels=\\{5, 7, other\\}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# ________________________    Data Loader    ________________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "## Load train data\n",
        "batch_size = 512\n",
        "train_loader, test_loader = load_and_process_data(bs=batch_size,\n",
        "                                                  mapping_label_to_encode=map_label_card_3_5)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "n_classes = 3\n",
        "n_epochs = 20\n",
        "lr = 0.005\n",
        "dict_optim_cfg = {\"momentum\":0.9 ,\"nesterov\": True}\n",
        "# -------------------------------------------------------------------\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model instance    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "model_toy, criterion_toy, optimizer_toy = models_factory(model_type=\"toy_model\",\n",
        "                                                         optim_cfg=dict_optim_cfg,\n",
        "                                                         nb_classes=n_classes)\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 instance    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# Initialize model, loss, optimizer and sgld sampler\n",
        "## taking an untrained resnet18\n",
        "\n",
        "models_resnet, criterion_resnet, optimizer_resnet = models_factory(model_type=\"toy_model\",\n",
        "                                                                   optim_cfg=dict_optim_cfg,\n",
        "                                                                   nb_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Resnet18 training    _____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "\n",
        "train_losses_resnet_xp1_10 = []\n",
        "val_losses_resnet_xp1_10 = []\n",
        "models_resnet_xp1_10 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_resnet18,\n",
        "                                       optimizer_resnet18,\n",
        "                                       criterion_resnet18,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_resnet18,\n",
        "                                  criterion_resnet18,\n",
        "                                  test_loader)\n",
        "    train_losses_resnet_xp1_10.append(train_loss)\n",
        "    val_losses_resnet_xp1_10.append(val_loss)\n",
        "    models_resnet_xp1_10 += [copy.deepcopy(model_resnet18)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_resnet_xp1_10, \"XP1/card_3-case_5/resnet_models.pth\")\n",
        "\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "# _____________________    Toy model training    ____________________ #\n",
        "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n",
        "train_losses_toy_xp1_10 = []\n",
        "val_losses_toy_xp1_10 = []\n",
        "models_toy_xp1_10 = []\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train_step(model_toy,\n",
        "                                       optimizer_toy,\n",
        "                                       criterion_toy,\n",
        "                                       train_loader)\n",
        "    val_loss, val_acc = val_step(model_toy,\n",
        "                                  criterion_toy,\n",
        "                                  test_loader)\n",
        "    train_losses_toy_xp1_10.append(train_loss)\n",
        "    val_losses_toy_xp1_10.append(val_loss)\n",
        "    models_toy_xp1_10 += [copy.deepcopy(model_toy)]\n",
        "\n",
        "    print_step_report(epoch=epoch,\n",
        "                      train_loss=train_loss,\n",
        "                      val_loss=val_loss,\n",
        "                      train_acc=train_acc,\n",
        "                      val_acc=val_acc)\n",
        "\n",
        "torch.save(models_toy_xp1_10, \"XP1/card_3-case_5/toy_models.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALax802SO-SS"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=4$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 4 classes\n",
        "* Resnet18 model for 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHHkYi2UQBkE"
      },
      "outputs": [],
      "source": [
        "# keys are the original label, values are the new labels\n",
        "# [{2, 6, other} ; {3, 6, other} ; {0, 4, other} ; {8, 9, other} ; {5, 7, other}]\n",
        "map_label_card_4_1 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_2 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_3 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_4 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
        "map_label_card_4_5 = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuC3UmWFO-JA"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=5$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 5 classes\n",
        "* Resnet18 model for 5 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9nTnDMpQB9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TViZYvtfPDkQ"
      },
      "source": [
        "### Settings and runs label sets $Card(\\mathcal{L}abels)=10$\n",
        "\n",
        "* Labels modification and data loader\n",
        "* Toy model for 10 classes\n",
        "* Resnet18 model for 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiFPlfl4QCup"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5naegrOpGP"
      },
      "source": [
        "## Displays Î» ð£ð  $\\mathcal{L}$ððððð "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "58TfSEILwxiV",
        "outputId": "5908e9e8-6653-4dca-d255-4e7cc9210405"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\", color=PRIMARY)\n",
        "ax1.plot(train_losses, label=\"Train Loss\", color=PRIMARY)\n",
        "ax1.plot(test_losses, label=\"Test Loss\", color=PRIMARY_LIGHT)\n",
        "ax1.tick_params(axis=\"y\", labelcolor=PRIMARY)\n",
        "ax1.legend(loc=\"lower left\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(r\"Local Learning Coefficient, $\\hat \\lambda$\", color=SECONDARY)\n",
        "ax2.plot(rlct_estimates_sgnht, label=\"SGNHT\", color=SECONDARY)\n",
        "ax2.plot(rlct_estimates_sgld, label=\"SGLD\", color=SECONDARY_LIGHT)\n",
        "ax2.tick_params(axis=\"y\", labelcolor=SECONDARY)\n",
        "ax2.legend(loc=\"center right\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7RyqF-3zmsM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cb7SG-MJmEAb",
        "ndBsAQfymIpo",
        "w1LHW2tDmPef",
        "J9ib7yhNmglL",
        "PbCKghWUmsk7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
